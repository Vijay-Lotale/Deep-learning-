{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQfPXufrR5hR"
      },
      "outputs": [],
      "source": [
        "# Importing all the basic and needful libraries to build the model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense , Dropout"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the dataset .\n",
        "df = pd.read_csv(\"weatherAUS.csv\")"
      ],
      "metadata": {
        "id": "OOV7vio0SFHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "vEqy5HLySzwQ",
        "outputId": "64f2f1a8-9c60-4007-e864-e9f0cbbafbde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
              "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
              "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
              "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
              "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
              "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
              "\n",
              "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  Humidity3pm  \\\n",
              "0           W           44.0          W  ...        71.0         22.0   \n",
              "1         WNW           44.0        NNW  ...        44.0         25.0   \n",
              "2         WSW           46.0          W  ...        38.0         30.0   \n",
              "3          NE           24.0         SE  ...        45.0         16.0   \n",
              "4           W           41.0        ENE  ...        82.0         33.0   \n",
              "\n",
              "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
              "0       1007.7       1007.1       8.0       NaN     16.9     21.8         No   \n",
              "1       1010.6       1007.8       NaN       NaN     17.2     24.3         No   \n",
              "2       1007.6       1008.7       NaN       2.0     21.0     23.2         No   \n",
              "3       1017.6       1012.8       NaN       NaN     18.1     26.5         No   \n",
              "4       1010.8       1006.0       7.0       8.0     17.8     29.7         No   \n",
              "\n",
              "   RainTomorrow  \n",
              "0            No  \n",
              "1            No  \n",
              "2            No  \n",
              "3            No  \n",
              "4            No  \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c8febe8c-3c12-446d-9030-408e017b5ef5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Location</th>\n",
              "      <th>MinTemp</th>\n",
              "      <th>MaxTemp</th>\n",
              "      <th>Rainfall</th>\n",
              "      <th>Evaporation</th>\n",
              "      <th>Sunshine</th>\n",
              "      <th>WindGustDir</th>\n",
              "      <th>WindGustSpeed</th>\n",
              "      <th>WindDir9am</th>\n",
              "      <th>...</th>\n",
              "      <th>Humidity9am</th>\n",
              "      <th>Humidity3pm</th>\n",
              "      <th>Pressure9am</th>\n",
              "      <th>Pressure3pm</th>\n",
              "      <th>Cloud9am</th>\n",
              "      <th>Cloud3pm</th>\n",
              "      <th>Temp9am</th>\n",
              "      <th>Temp3pm</th>\n",
              "      <th>RainToday</th>\n",
              "      <th>RainTomorrow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2008-12-01</td>\n",
              "      <td>Albury</td>\n",
              "      <td>13.4</td>\n",
              "      <td>22.9</td>\n",
              "      <td>0.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>W</td>\n",
              "      <td>44.0</td>\n",
              "      <td>W</td>\n",
              "      <td>...</td>\n",
              "      <td>71.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1007.7</td>\n",
              "      <td>1007.1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.9</td>\n",
              "      <td>21.8</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2008-12-02</td>\n",
              "      <td>Albury</td>\n",
              "      <td>7.4</td>\n",
              "      <td>25.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>WNW</td>\n",
              "      <td>44.0</td>\n",
              "      <td>NNW</td>\n",
              "      <td>...</td>\n",
              "      <td>44.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1010.6</td>\n",
              "      <td>1007.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17.2</td>\n",
              "      <td>24.3</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2008-12-03</td>\n",
              "      <td>Albury</td>\n",
              "      <td>12.9</td>\n",
              "      <td>25.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>WSW</td>\n",
              "      <td>46.0</td>\n",
              "      <td>W</td>\n",
              "      <td>...</td>\n",
              "      <td>38.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1007.6</td>\n",
              "      <td>1008.7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>23.2</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2008-12-04</td>\n",
              "      <td>Albury</td>\n",
              "      <td>9.2</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NE</td>\n",
              "      <td>24.0</td>\n",
              "      <td>SE</td>\n",
              "      <td>...</td>\n",
              "      <td>45.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1017.6</td>\n",
              "      <td>1012.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18.1</td>\n",
              "      <td>26.5</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2008-12-05</td>\n",
              "      <td>Albury</td>\n",
              "      <td>17.5</td>\n",
              "      <td>32.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>W</td>\n",
              "      <td>41.0</td>\n",
              "      <td>ENE</td>\n",
              "      <td>...</td>\n",
              "      <td>82.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>1010.8</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>29.7</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8febe8c-3c12-446d-9030-408e017b5ef5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c8febe8c-3c12-446d-9030-408e017b5ef5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c8febe8c-3c12-446d-9030-408e017b5ef5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the info of dataset with info function .\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rjYaT-QS3kZ",
        "outputId": "d2c99d8e-b4e3-45e4-d631-d158947d4b1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 145460 entries, 0 to 145459\n",
            "Data columns (total 23 columns):\n",
            " #   Column         Non-Null Count   Dtype  \n",
            "---  ------         --------------   -----  \n",
            " 0   Date           145460 non-null  object \n",
            " 1   Location       145460 non-null  object \n",
            " 2   MinTemp        143975 non-null  float64\n",
            " 3   MaxTemp        144199 non-null  float64\n",
            " 4   Rainfall       142199 non-null  float64\n",
            " 5   Evaporation    82670 non-null   float64\n",
            " 6   Sunshine       75625 non-null   float64\n",
            " 7   WindGustDir    135134 non-null  object \n",
            " 8   WindGustSpeed  135197 non-null  float64\n",
            " 9   WindDir9am     134894 non-null  object \n",
            " 10  WindDir3pm     141232 non-null  object \n",
            " 11  WindSpeed9am   143693 non-null  float64\n",
            " 12  WindSpeed3pm   142398 non-null  float64\n",
            " 13  Humidity9am    142806 non-null  float64\n",
            " 14  Humidity3pm    140953 non-null  float64\n",
            " 15  Pressure9am    130395 non-null  float64\n",
            " 16  Pressure3pm    130432 non-null  float64\n",
            " 17  Cloud9am       89572 non-null   float64\n",
            " 18  Cloud3pm       86102 non-null   float64\n",
            " 19  Temp9am        143693 non-null  float64\n",
            " 20  Temp3pm        141851 non-null  float64\n",
            " 21  RainToday      142199 non-null  object \n",
            " 22  RainTomorrow   142193 non-null  object \n",
            "dtypes: float64(16), object(7)\n",
            "memory usage: 25.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "ByAmonm6S6i_",
        "outputId": "63dae4dd-e902-4a19-e4ba-9bd800eeed8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             MinTemp        MaxTemp       Rainfall   Evaporation  \\\n",
              "count  143975.000000  144199.000000  142199.000000  82670.000000   \n",
              "mean       12.194034      23.221348       2.360918      5.468232   \n",
              "std         6.398495       7.119049       8.478060      4.193704   \n",
              "min        -8.500000      -4.800000       0.000000      0.000000   \n",
              "25%         7.600000      17.900000       0.000000      2.600000   \n",
              "50%        12.000000      22.600000       0.000000      4.800000   \n",
              "75%        16.900000      28.200000       0.800000      7.400000   \n",
              "max        33.900000      48.100000     371.000000    145.000000   \n",
              "\n",
              "           Sunshine  WindGustSpeed   WindSpeed9am   WindSpeed3pm  \\\n",
              "count  75625.000000  135197.000000  143693.000000  142398.000000   \n",
              "mean       7.611178      40.035230      14.043426      18.662657   \n",
              "std        3.785483      13.607062       8.915375       8.809800   \n",
              "min        0.000000       6.000000       0.000000       0.000000   \n",
              "25%        4.800000      31.000000       7.000000      13.000000   \n",
              "50%        8.400000      39.000000      13.000000      19.000000   \n",
              "75%       10.600000      48.000000      19.000000      24.000000   \n",
              "max       14.500000     135.000000     130.000000      87.000000   \n",
              "\n",
              "         Humidity9am    Humidity3pm   Pressure9am    Pressure3pm  \\\n",
              "count  142806.000000  140953.000000  130395.00000  130432.000000   \n",
              "mean       68.880831      51.539116    1017.64994    1015.255889   \n",
              "std        19.029164      20.795902       7.10653       7.037414   \n",
              "min         0.000000       0.000000     980.50000     977.100000   \n",
              "25%        57.000000      37.000000    1012.90000    1010.400000   \n",
              "50%        70.000000      52.000000    1017.60000    1015.200000   \n",
              "75%        83.000000      66.000000    1022.40000    1020.000000   \n",
              "max       100.000000     100.000000    1041.00000    1039.600000   \n",
              "\n",
              "           Cloud9am      Cloud3pm        Temp9am       Temp3pm  \n",
              "count  89572.000000  86102.000000  143693.000000  141851.00000  \n",
              "mean       4.447461      4.509930      16.990631      21.68339  \n",
              "std        2.887159      2.720357       6.488753       6.93665  \n",
              "min        0.000000      0.000000      -7.200000      -5.40000  \n",
              "25%        1.000000      2.000000      12.300000      16.60000  \n",
              "50%        5.000000      5.000000      16.700000      21.10000  \n",
              "75%        7.000000      7.000000      21.600000      26.40000  \n",
              "max        9.000000      9.000000      40.200000      46.70000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b598373d-437e-468a-b38b-fdfbd3314643\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MinTemp</th>\n",
              "      <th>MaxTemp</th>\n",
              "      <th>Rainfall</th>\n",
              "      <th>Evaporation</th>\n",
              "      <th>Sunshine</th>\n",
              "      <th>WindGustSpeed</th>\n",
              "      <th>WindSpeed9am</th>\n",
              "      <th>WindSpeed3pm</th>\n",
              "      <th>Humidity9am</th>\n",
              "      <th>Humidity3pm</th>\n",
              "      <th>Pressure9am</th>\n",
              "      <th>Pressure3pm</th>\n",
              "      <th>Cloud9am</th>\n",
              "      <th>Cloud3pm</th>\n",
              "      <th>Temp9am</th>\n",
              "      <th>Temp3pm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>143975.000000</td>\n",
              "      <td>144199.000000</td>\n",
              "      <td>142199.000000</td>\n",
              "      <td>82670.000000</td>\n",
              "      <td>75625.000000</td>\n",
              "      <td>135197.000000</td>\n",
              "      <td>143693.000000</td>\n",
              "      <td>142398.000000</td>\n",
              "      <td>142806.000000</td>\n",
              "      <td>140953.000000</td>\n",
              "      <td>130395.00000</td>\n",
              "      <td>130432.000000</td>\n",
              "      <td>89572.000000</td>\n",
              "      <td>86102.000000</td>\n",
              "      <td>143693.000000</td>\n",
              "      <td>141851.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>12.194034</td>\n",
              "      <td>23.221348</td>\n",
              "      <td>2.360918</td>\n",
              "      <td>5.468232</td>\n",
              "      <td>7.611178</td>\n",
              "      <td>40.035230</td>\n",
              "      <td>14.043426</td>\n",
              "      <td>18.662657</td>\n",
              "      <td>68.880831</td>\n",
              "      <td>51.539116</td>\n",
              "      <td>1017.64994</td>\n",
              "      <td>1015.255889</td>\n",
              "      <td>4.447461</td>\n",
              "      <td>4.509930</td>\n",
              "      <td>16.990631</td>\n",
              "      <td>21.68339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>6.398495</td>\n",
              "      <td>7.119049</td>\n",
              "      <td>8.478060</td>\n",
              "      <td>4.193704</td>\n",
              "      <td>3.785483</td>\n",
              "      <td>13.607062</td>\n",
              "      <td>8.915375</td>\n",
              "      <td>8.809800</td>\n",
              "      <td>19.029164</td>\n",
              "      <td>20.795902</td>\n",
              "      <td>7.10653</td>\n",
              "      <td>7.037414</td>\n",
              "      <td>2.887159</td>\n",
              "      <td>2.720357</td>\n",
              "      <td>6.488753</td>\n",
              "      <td>6.93665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-8.500000</td>\n",
              "      <td>-4.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>980.50000</td>\n",
              "      <td>977.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-7.200000</td>\n",
              "      <td>-5.40000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>7.600000</td>\n",
              "      <td>17.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.600000</td>\n",
              "      <td>4.800000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>1012.90000</td>\n",
              "      <td>1010.400000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>12.300000</td>\n",
              "      <td>16.60000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>12.000000</td>\n",
              "      <td>22.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.800000</td>\n",
              "      <td>8.400000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>1017.60000</td>\n",
              "      <td>1015.200000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>16.700000</td>\n",
              "      <td>21.10000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>16.900000</td>\n",
              "      <td>28.200000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>7.400000</td>\n",
              "      <td>10.600000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>1022.40000</td>\n",
              "      <td>1020.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>21.600000</td>\n",
              "      <td>26.40000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>33.900000</td>\n",
              "      <td>48.100000</td>\n",
              "      <td>371.000000</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>14.500000</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1041.00000</td>\n",
              "      <td>1039.600000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>40.200000</td>\n",
              "      <td>46.70000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b598373d-437e-468a-b38b-fdfbd3314643')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b598373d-437e-468a-b38b-fdfbd3314643 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b598373d-437e-468a-b38b-fdfbd3314643');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for the null values present in the dataset .\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFmuTUD6TB93",
        "outputId": "4f9d081f-c926-407d-874c-e2b0f97a394f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date                 0\n",
              "Location             0\n",
              "MinTemp           1485\n",
              "MaxTemp           1261\n",
              "Rainfall          3261\n",
              "Evaporation      62790\n",
              "Sunshine         69835\n",
              "WindGustDir      10326\n",
              "WindGustSpeed    10263\n",
              "WindDir9am       10566\n",
              "WindDir3pm        4228\n",
              "WindSpeed9am      1767\n",
              "WindSpeed3pm      3062\n",
              "Humidity9am       2654\n",
              "Humidity3pm       4507\n",
              "Pressure9am      15065\n",
              "Pressure3pm      15028\n",
              "Cloud9am         55888\n",
              "Cloud3pm         59358\n",
              "Temp9am           1767\n",
              "Temp3pm           3609\n",
              "RainToday         3261\n",
              "RainTomorrow      3267\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**filling null values of object datatype with Mode .**"
      ],
      "metadata": {
        "id": "ZIQ7Mfi4TTna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"WindGustDir\"].fillna(df[\"WindGustDir\"].mode()[0],inplace=True)"
      ],
      "metadata": {
        "id": "Ig81mxYOTOY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"WindDir9am\"].fillna(df[\"WindDir9am\"].mode()[0],inplace=True)"
      ],
      "metadata": {
        "id": "w5_cdnLRTyJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"WindDir3pm\"].fillna(df[\"WindDir3pm\"].mode()[0],inplace=True)"
      ],
      "metadata": {
        "id": "-u1DidVPT8sP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"RainToday\"].fillna(df[\"RainToday\"].mode()[0],inplace=True)"
      ],
      "metadata": {
        "id": "THCY0aVQUB35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"RainTomorrow\"].fillna(df[\"RainTomorrow\"].mode()[0],inplace=True)"
      ],
      "metadata": {
        "id": "KWf3JMtlUM1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filled the null values of object datatype columns with mode of that column .\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k--MyT4pUS_W",
        "outputId": "44adf319-a77e-479d-fd7a-151164a5da70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date                 0\n",
              "Location             0\n",
              "MinTemp           1485\n",
              "MaxTemp           1261\n",
              "Rainfall          3261\n",
              "Evaporation      62790\n",
              "Sunshine         69835\n",
              "WindGustDir          0\n",
              "WindGustSpeed    10263\n",
              "WindDir9am           0\n",
              "WindDir3pm           0\n",
              "WindSpeed9am      1767\n",
              "WindSpeed3pm      3062\n",
              "Humidity9am       2654\n",
              "Humidity3pm       4507\n",
              "Pressure9am      15065\n",
              "Pressure3pm      15028\n",
              "Cloud9am         55888\n",
              "Cloud3pm         59358\n",
              "Temp9am           1767\n",
              "Temp3pm           3609\n",
              "RainToday            0\n",
              "RainTomorrow         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the binary distribution of target variable .\n",
        "df[\"RainTomorrow\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzYyreVlUVVs",
        "outputId": "77212e32-4af1-400e-e4fd-2a6215885ca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "No     113583\n",
              "Yes     31877\n",
              "Name: RainTomorrow, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"RainTomorrow\"].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9yCLfRrUsVd",
        "outputId": "24b4c95e-cbfd-4f42-ac46-e42d2fd3ff81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['No', 'Yes'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Droping some features who has more null values .\n",
        "df.drop(columns = [\"Evaporation\",\"Sunshine\",\"Date\",\"Cloud9am\",\"Cloud3pm\"],inplace = True)"
      ],
      "metadata": {
        "id": "9tOZUYWxUw07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8ZevbHvc3-y",
        "outputId": "dabbc3d5-4059-4a66-caaa-75d112333df0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 145460 entries, 0 to 145459\n",
            "Data columns (total 18 columns):\n",
            " #   Column         Non-Null Count   Dtype  \n",
            "---  ------         --------------   -----  \n",
            " 0   Location       145460 non-null  object \n",
            " 1   MinTemp        143975 non-null  float64\n",
            " 2   MaxTemp        144199 non-null  float64\n",
            " 3   Rainfall       142199 non-null  float64\n",
            " 4   WindGustDir    145460 non-null  object \n",
            " 5   WindGustSpeed  135197 non-null  float64\n",
            " 6   WindDir9am     145460 non-null  object \n",
            " 7   WindDir3pm     145460 non-null  object \n",
            " 8   WindSpeed9am   143693 non-null  float64\n",
            " 9   WindSpeed3pm   142398 non-null  float64\n",
            " 10  Humidity9am    142806 non-null  float64\n",
            " 11  Humidity3pm    140953 non-null  float64\n",
            " 12  Pressure9am    130395 non-null  float64\n",
            " 13  Pressure3pm    130432 non-null  float64\n",
            " 14  Temp9am        143693 non-null  float64\n",
            " 15  Temp3pm        141851 non-null  float64\n",
            " 16  RainToday      145460 non-null  object \n",
            " 17  RainTomorrow   145460 non-null  object \n",
            "dtypes: float64(12), object(6)\n",
            "memory usage: 20.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating list of object datatype columns for label encoding .\n",
        "obj_features = [\"Location\",\"WindGustDir\",\"WindDir9am\",\"WindDir3pm\",\"RainToday\"]"
      ],
      "metadata": {
        "id": "HK_6T_zHc6C9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Labelencoder for converting object variables to int .\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "IsSNpV1cdhHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()"
      ],
      "metadata": {
        "id": "pUboeCMVdwED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying labelencoding with the help of loop on list created with object datatype columns .\n",
        "for i in obj_features:\n",
        "  df[i] = le.fit_transform(df[i])"
      ],
      "metadata": {
        "id": "fiv37EB1dzNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2_LIvCQd89i",
        "outputId": "7efd4ebd-f736-4bb0-96f8-c752f30500a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 145460 entries, 0 to 145459\n",
            "Data columns (total 18 columns):\n",
            " #   Column         Non-Null Count   Dtype  \n",
            "---  ------         --------------   -----  \n",
            " 0   Location       145460 non-null  int64  \n",
            " 1   MinTemp        143975 non-null  float64\n",
            " 2   MaxTemp        144199 non-null  float64\n",
            " 3   Rainfall       142199 non-null  float64\n",
            " 4   WindGustDir    145460 non-null  int64  \n",
            " 5   WindGustSpeed  135197 non-null  float64\n",
            " 6   WindDir9am     145460 non-null  int64  \n",
            " 7   WindDir3pm     145460 non-null  int64  \n",
            " 8   WindSpeed9am   143693 non-null  float64\n",
            " 9   WindSpeed3pm   142398 non-null  float64\n",
            " 10  Humidity9am    142806 non-null  float64\n",
            " 11  Humidity3pm    140953 non-null  float64\n",
            " 12  Pressure9am    130395 non-null  float64\n",
            " 13  Pressure3pm    130432 non-null  float64\n",
            " 14  Temp9am        143693 non-null  float64\n",
            " 15  Temp3pm        141851 non-null  float64\n",
            " 16  RainToday      145460 non-null  int64  \n",
            " 17  RainTomorrow   145460 non-null  object \n",
            "dtypes: float64(12), int64(5), object(1)\n",
            "memory usage: 20.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-36U_5IVd-uB",
        "outputId": "8a604a6a-fe29-45d0-bf2c-2ae64524d37e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Location             0\n",
              "MinTemp           1485\n",
              "MaxTemp           1261\n",
              "Rainfall          3261\n",
              "WindGustDir          0\n",
              "WindGustSpeed    10263\n",
              "WindDir9am           0\n",
              "WindDir3pm           0\n",
              "WindSpeed9am      1767\n",
              "WindSpeed3pm      3062\n",
              "Humidity9am       2654\n",
              "Humidity3pm       4507\n",
              "Pressure9am      15065\n",
              "Pressure3pm      15028\n",
              "Temp9am           1767\n",
              "Temp3pm           3609\n",
              "RainToday            0\n",
              "RainTomorrow         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling the remaining null values present in dataset .\n",
        "df[\"MinTemp\"].fillna(df[\"MinTemp\"].mean(),inplace=True)"
      ],
      "metadata": {
        "id": "Bd1eym0MeHuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"MaxTemp\"].fillna(df[\"MaxTemp\"].mean(),inplace=True)"
      ],
      "metadata": {
        "id": "q5rhcTaxeVSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Rainfall\"].fillna(df[\"Rainfall\"].mean(),inplace=True)"
      ],
      "metadata": {
        "id": "qwKEH_WneaZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"WindGustSpeed\"].fillna(df[\"WindGustSpeed\"].mean(),inplace=True)"
      ],
      "metadata": {
        "id": "i2uAP8jiefkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"WindSpeed9am\"].fillna(df[\"WindSpeed9am\"].mean(),inplace=True)"
      ],
      "metadata": {
        "id": "znZADAc8elhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"WindSpeed3pm\"].fillna(df[\"WindSpeed3pm\"].mean(),inplace=True)"
      ],
      "metadata": {
        "id": "1QycXg05etA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Humidity9am\"].fillna(df[\"Humidity9am\"].mean(),inplace=True)"
      ],
      "metadata": {
        "id": "W1dB3KcdezTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Humidity3pm\"].fillna(df[\"Humidity3pm\"].mean(),inplace=True)"
      ],
      "metadata": {
        "id": "ZS3zDdDie9Te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Pressure9am\"].fillna(df[\"Pressure9am\"].mean(),inplace=True)"
      ],
      "metadata": {
        "id": "t56BUbOjfDOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Pressure3pm\"].fillna(df[\"Pressure3pm\"].mean(),inplace=True)"
      ],
      "metadata": {
        "id": "nGl906XlfJyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Temp9am\"].fillna(df[\"Temp9am\"].mean(),inplace=True)"
      ],
      "metadata": {
        "id": "SoufqemTfRkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Temp3pm\"].fillna(df[\"Temp3pm\"].mean(),inplace=True)"
      ],
      "metadata": {
        "id": "VJZQ4UesfXTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLaiAQRKfbT5",
        "outputId": "b5d3408e-769d-487a-9b85-2a3a46a6a7aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Location         0\n",
              "MinTemp          0\n",
              "MaxTemp          0\n",
              "Rainfall         0\n",
              "WindGustDir      0\n",
              "WindGustSpeed    0\n",
              "WindDir9am       0\n",
              "WindDir3pm       0\n",
              "WindSpeed9am     0\n",
              "WindSpeed3pm     0\n",
              "Humidity9am      0\n",
              "Humidity3pm      0\n",
              "Pressure9am      0\n",
              "Pressure3pm      0\n",
              "Temp9am          0\n",
              "Temp3pm          0\n",
              "RainToday        0\n",
              "RainTomorrow     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlQlFHnnfeLh",
        "outputId": "2eb7ede6-3ada-4d5e-8a33-3e2d78aa0035"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 145460 entries, 0 to 145459\n",
            "Data columns (total 18 columns):\n",
            " #   Column         Non-Null Count   Dtype  \n",
            "---  ------         --------------   -----  \n",
            " 0   Location       145460 non-null  int64  \n",
            " 1   MinTemp        145460 non-null  float64\n",
            " 2   MaxTemp        145460 non-null  float64\n",
            " 3   Rainfall       145460 non-null  float64\n",
            " 4   WindGustDir    145460 non-null  int64  \n",
            " 5   WindGustSpeed  145460 non-null  float64\n",
            " 6   WindDir9am     145460 non-null  int64  \n",
            " 7   WindDir3pm     145460 non-null  int64  \n",
            " 8   WindSpeed9am   145460 non-null  float64\n",
            " 9   WindSpeed3pm   145460 non-null  float64\n",
            " 10  Humidity9am    145460 non-null  float64\n",
            " 11  Humidity3pm    145460 non-null  float64\n",
            " 12  Pressure9am    145460 non-null  float64\n",
            " 13  Pressure3pm    145460 non-null  float64\n",
            " 14  Temp9am        145460 non-null  float64\n",
            " 15  Temp3pm        145460 non-null  float64\n",
            " 16  RainToday      145460 non-null  int64  \n",
            " 17  RainTomorrow   145460 non-null  object \n",
            "dtypes: float64(12), int64(5), object(1)\n",
            "memory usage: 20.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"RainTomorrow\"] = le.fit_transform(df[\"RainTomorrow\"])"
      ],
      "metadata": {
        "id": "RL3url3rfgJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "26QMhCkef8Nr",
        "outputId": "32c2e984-351d-4f83-fa73-cf294a22919b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Location  MinTemp  MaxTemp  Rainfall  WindGustDir  WindGustSpeed  \\\n",
              "0         2     13.4     22.9       0.6           13           44.0   \n",
              "1         2      7.4     25.1       0.0           14           44.0   \n",
              "2         2     12.9     25.7       0.0           15           46.0   \n",
              "3         2      9.2     28.0       0.0            4           24.0   \n",
              "4         2     17.5     32.3       1.0           13           41.0   \n",
              "\n",
              "   WindDir9am  WindDir3pm  WindSpeed9am  WindSpeed3pm  Humidity9am  \\\n",
              "0          13          14          20.0          24.0         71.0   \n",
              "1           6          15           4.0          22.0         44.0   \n",
              "2          13          15          19.0          26.0         38.0   \n",
              "3           9           0          11.0           9.0         45.0   \n",
              "4           1           7           7.0          20.0         82.0   \n",
              "\n",
              "   Humidity3pm  Pressure9am  Pressure3pm  Temp9am  Temp3pm  RainToday  \\\n",
              "0         22.0       1007.7       1007.1     16.9     21.8          0   \n",
              "1         25.0       1010.6       1007.8     17.2     24.3          0   \n",
              "2         30.0       1007.6       1008.7     21.0     23.2          0   \n",
              "3         16.0       1017.6       1012.8     18.1     26.5          0   \n",
              "4         33.0       1010.8       1006.0     17.8     29.7          0   \n",
              "\n",
              "   RainTomorrow  \n",
              "0             0  \n",
              "1             0  \n",
              "2             0  \n",
              "3             0  \n",
              "4             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98ae32b4-cdd3-49af-936e-91704c3f30db\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Location</th>\n",
              "      <th>MinTemp</th>\n",
              "      <th>MaxTemp</th>\n",
              "      <th>Rainfall</th>\n",
              "      <th>WindGustDir</th>\n",
              "      <th>WindGustSpeed</th>\n",
              "      <th>WindDir9am</th>\n",
              "      <th>WindDir3pm</th>\n",
              "      <th>WindSpeed9am</th>\n",
              "      <th>WindSpeed3pm</th>\n",
              "      <th>Humidity9am</th>\n",
              "      <th>Humidity3pm</th>\n",
              "      <th>Pressure9am</th>\n",
              "      <th>Pressure3pm</th>\n",
              "      <th>Temp9am</th>\n",
              "      <th>Temp3pm</th>\n",
              "      <th>RainToday</th>\n",
              "      <th>RainTomorrow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>13.4</td>\n",
              "      <td>22.9</td>\n",
              "      <td>0.6</td>\n",
              "      <td>13</td>\n",
              "      <td>44.0</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>20.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1007.7</td>\n",
              "      <td>1007.1</td>\n",
              "      <td>16.9</td>\n",
              "      <td>21.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>7.4</td>\n",
              "      <td>25.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14</td>\n",
              "      <td>44.0</td>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "      <td>4.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1010.6</td>\n",
              "      <td>1007.8</td>\n",
              "      <td>17.2</td>\n",
              "      <td>24.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>12.9</td>\n",
              "      <td>25.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15</td>\n",
              "      <td>46.0</td>\n",
              "      <td>13</td>\n",
              "      <td>15</td>\n",
              "      <td>19.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1007.6</td>\n",
              "      <td>1008.7</td>\n",
              "      <td>21.0</td>\n",
              "      <td>23.2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>9.2</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>24.0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1017.6</td>\n",
              "      <td>1012.8</td>\n",
              "      <td>18.1</td>\n",
              "      <td>26.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>17.5</td>\n",
              "      <td>32.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13</td>\n",
              "      <td>41.0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>7.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>1010.8</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>29.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98ae32b4-cdd3-49af-936e-91704c3f30db')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-98ae32b4-cdd3-49af-936e-91704c3f30db button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-98ae32b4-cdd3-49af-936e-91704c3f30db');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting data into input features and output feature\n",
        "\n",
        "x = df.iloc[:,:-1].values\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2m-fJr8gBoE",
        "outputId": "fbb76805-77f3-4c0b-8cef-47feab290a74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.        , 13.4       , 22.9       , ..., 16.9       ,\n",
              "        21.8       ,  0.        ],\n",
              "       [ 2.        ,  7.4       , 25.1       , ..., 17.2       ,\n",
              "        24.3       ,  0.        ],\n",
              "       [ 2.        , 12.9       , 25.7       , ..., 21.        ,\n",
              "        23.2       ,  0.        ],\n",
              "       ...,\n",
              "       [41.        ,  5.4       , 26.9       , ..., 12.5       ,\n",
              "        26.1       ,  0.        ],\n",
              "       [41.        ,  7.8       , 27.        , ..., 15.1       ,\n",
              "        26.        ,  0.        ],\n",
              "       [41.        , 14.9       , 23.22134828, ..., 15.        ,\n",
              "        20.9       ,  0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df[\"RainTomorrow\"].values\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_FMdCn4jiS5",
        "outputId": "6e18cad3-3e7d-46e6-dd10-0b666665b45c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "LarqFehGjwr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.3,random_state=1)"
      ],
      "metadata": {
        "id": "u2tc82pMj1vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# performing feature scaling to scale down the values .\n",
        "from sklearn.preprocessing import  StandardScaler"
      ],
      "metadata": {
        "id": "1jRFpqnsj6P0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = StandardScaler()"
      ],
      "metadata": {
        "id": "zZHInepEj8sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Appling feature scaling on trainging and testing data of input fratures .\n",
        "xtrain=sc.fit_transform(xtrain)\n",
        "xtest=sc.transform(xtest)"
      ],
      "metadata": {
        "id": "U3F7dKdKj-1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "mwNZiBYwkBPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
      ],
      "metadata": {
        "id": "GpUXMscokEHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building an ANN Model on dataset\n",
        "\n",
        "ann = Sequential()"
      ],
      "metadata": {
        "id": "qlbc-CfckLbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(Dense(units=128,activation=\"relu\"))\n",
        "ann.add(Dropout(rate = 0.2))\n",
        "\n",
        "ann.add(Dense(units=100,activation=\"relu\"))\n",
        "ann.add(Dropout(rate = 0.2))\n",
        "\n",
        "ann.add(Dense(units=1,activation=\"sigmoid\"))"
      ],
      "metadata": {
        "id": "anO6rtLCkO0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "eY4qishuksyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.fit(xtrain,ytrain,epochs=300,validation_data=(xtest, ytest),verbose=1,batch_size=1000,callbacks=[early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2uGydeTkvxo",
        "outputId": "fef535d8-268f-4133-d745-8519dae21c1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "102/102 [==============================] - 5s 35ms/step - loss: 0.5338 - accuracy: 0.7792 - val_loss: 0.4800 - val_accuracy: 0.7910\n",
            "Epoch 2/300\n",
            "102/102 [==============================] - 2s 22ms/step - loss: 0.4715 - accuracy: 0.7931 - val_loss: 0.4376 - val_accuracy: 0.8136\n",
            "Epoch 3/300\n",
            "102/102 [==============================] - 2s 21ms/step - loss: 0.4404 - accuracy: 0.8068 - val_loss: 0.4154 - val_accuracy: 0.8223\n",
            "Epoch 4/300\n",
            "102/102 [==============================] - 2s 21ms/step - loss: 0.4235 - accuracy: 0.8140 - val_loss: 0.4028 - val_accuracy: 0.8280\n",
            "Epoch 5/300\n",
            "102/102 [==============================] - 2s 22ms/step - loss: 0.4135 - accuracy: 0.8192 - val_loss: 0.3946 - val_accuracy: 0.8310\n",
            "Epoch 6/300\n",
            "102/102 [==============================] - 3s 26ms/step - loss: 0.4072 - accuracy: 0.8214 - val_loss: 0.3891 - val_accuracy: 0.8322\n",
            "Epoch 7/300\n",
            "102/102 [==============================] - 2s 18ms/step - loss: 0.4030 - accuracy: 0.8243 - val_loss: 0.3853 - val_accuracy: 0.8338\n",
            "Epoch 8/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.4004 - accuracy: 0.8258 - val_loss: 0.3825 - val_accuracy: 0.8355\n",
            "Epoch 9/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3975 - accuracy: 0.8275 - val_loss: 0.3801 - val_accuracy: 0.8366\n",
            "Epoch 10/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3950 - accuracy: 0.8289 - val_loss: 0.3782 - val_accuracy: 0.8379\n",
            "Epoch 11/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3945 - accuracy: 0.8284 - val_loss: 0.3767 - val_accuracy: 0.8384\n",
            "Epoch 12/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3922 - accuracy: 0.8308 - val_loss: 0.3756 - val_accuracy: 0.8387\n",
            "Epoch 13/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3911 - accuracy: 0.8305 - val_loss: 0.3744 - val_accuracy: 0.8389\n",
            "Epoch 14/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3904 - accuracy: 0.8304 - val_loss: 0.3734 - val_accuracy: 0.8397\n",
            "Epoch 15/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3903 - accuracy: 0.8306 - val_loss: 0.3726 - val_accuracy: 0.8398\n",
            "Epoch 16/300\n",
            "102/102 [==============================] - 2s 16ms/step - loss: 0.3876 - accuracy: 0.8328 - val_loss: 0.3720 - val_accuracy: 0.8402\n",
            "Epoch 17/300\n",
            "102/102 [==============================] - 2s 17ms/step - loss: 0.3880 - accuracy: 0.8325 - val_loss: 0.3713 - val_accuracy: 0.8403\n",
            "Epoch 18/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3866 - accuracy: 0.8333 - val_loss: 0.3708 - val_accuracy: 0.8405\n",
            "Epoch 19/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3861 - accuracy: 0.8335 - val_loss: 0.3703 - val_accuracy: 0.8412\n",
            "Epoch 20/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3855 - accuracy: 0.8337 - val_loss: 0.3698 - val_accuracy: 0.8415\n",
            "Epoch 21/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3855 - accuracy: 0.8342 - val_loss: 0.3693 - val_accuracy: 0.8417\n",
            "Epoch 22/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3852 - accuracy: 0.8332 - val_loss: 0.3690 - val_accuracy: 0.8422\n",
            "Epoch 23/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3846 - accuracy: 0.8339 - val_loss: 0.3686 - val_accuracy: 0.8422\n",
            "Epoch 24/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3834 - accuracy: 0.8353 - val_loss: 0.3683 - val_accuracy: 0.8425\n",
            "Epoch 25/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3832 - accuracy: 0.8340 - val_loss: 0.3680 - val_accuracy: 0.8428\n",
            "Epoch 26/300\n",
            "102/102 [==============================] - 1s 13ms/step - loss: 0.3829 - accuracy: 0.8354 - val_loss: 0.3677 - val_accuracy: 0.8430\n",
            "Epoch 27/300\n",
            "102/102 [==============================] - 2s 18ms/step - loss: 0.3828 - accuracy: 0.8358 - val_loss: 0.3674 - val_accuracy: 0.8432\n",
            "Epoch 28/300\n",
            "102/102 [==============================] - 1s 13ms/step - loss: 0.3826 - accuracy: 0.8353 - val_loss: 0.3671 - val_accuracy: 0.8431\n",
            "Epoch 29/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3820 - accuracy: 0.8352 - val_loss: 0.3669 - val_accuracy: 0.8433\n",
            "Epoch 30/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3807 - accuracy: 0.8357 - val_loss: 0.3665 - val_accuracy: 0.8434\n",
            "Epoch 31/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3811 - accuracy: 0.8360 - val_loss: 0.3663 - val_accuracy: 0.8434\n",
            "Epoch 32/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3805 - accuracy: 0.8363 - val_loss: 0.3661 - val_accuracy: 0.8435\n",
            "Epoch 33/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3807 - accuracy: 0.8359 - val_loss: 0.3659 - val_accuracy: 0.8434\n",
            "Epoch 34/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3802 - accuracy: 0.8363 - val_loss: 0.3658 - val_accuracy: 0.8436\n",
            "Epoch 35/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3799 - accuracy: 0.8365 - val_loss: 0.3655 - val_accuracy: 0.8434\n",
            "Epoch 36/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3800 - accuracy: 0.8355 - val_loss: 0.3654 - val_accuracy: 0.8433\n",
            "Epoch 37/300\n",
            "102/102 [==============================] - 2s 18ms/step - loss: 0.3800 - accuracy: 0.8368 - val_loss: 0.3653 - val_accuracy: 0.8433\n",
            "Epoch 38/300\n",
            "102/102 [==============================] - 1s 14ms/step - loss: 0.3793 - accuracy: 0.8355 - val_loss: 0.3650 - val_accuracy: 0.8435\n",
            "Epoch 39/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3790 - accuracy: 0.8364 - val_loss: 0.3649 - val_accuracy: 0.8435\n",
            "Epoch 40/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3785 - accuracy: 0.8375 - val_loss: 0.3647 - val_accuracy: 0.8436\n",
            "Epoch 41/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3795 - accuracy: 0.8365 - val_loss: 0.3646 - val_accuracy: 0.8436\n",
            "Epoch 42/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3782 - accuracy: 0.8369 - val_loss: 0.3644 - val_accuracy: 0.8435\n",
            "Epoch 43/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3781 - accuracy: 0.8373 - val_loss: 0.3643 - val_accuracy: 0.8438\n",
            "Epoch 44/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3787 - accuracy: 0.8366 - val_loss: 0.3640 - val_accuracy: 0.8437\n",
            "Epoch 45/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3784 - accuracy: 0.8375 - val_loss: 0.3640 - val_accuracy: 0.8436\n",
            "Epoch 46/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3778 - accuracy: 0.8374 - val_loss: 0.3638 - val_accuracy: 0.8437\n",
            "Epoch 47/300\n",
            "102/102 [==============================] - 2s 17ms/step - loss: 0.3771 - accuracy: 0.8381 - val_loss: 0.3637 - val_accuracy: 0.8440\n",
            "Epoch 48/300\n",
            "102/102 [==============================] - 2s 16ms/step - loss: 0.3775 - accuracy: 0.8370 - val_loss: 0.3636 - val_accuracy: 0.8440\n",
            "Epoch 49/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3764 - accuracy: 0.8388 - val_loss: 0.3635 - val_accuracy: 0.8441\n",
            "Epoch 50/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3772 - accuracy: 0.8376 - val_loss: 0.3634 - val_accuracy: 0.8441\n",
            "Epoch 51/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3767 - accuracy: 0.8378 - val_loss: 0.3633 - val_accuracy: 0.8441\n",
            "Epoch 52/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3775 - accuracy: 0.8382 - val_loss: 0.3632 - val_accuracy: 0.8441\n",
            "Epoch 53/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3756 - accuracy: 0.8383 - val_loss: 0.3630 - val_accuracy: 0.8443\n",
            "Epoch 54/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3768 - accuracy: 0.8370 - val_loss: 0.3629 - val_accuracy: 0.8444\n",
            "Epoch 55/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3758 - accuracy: 0.8392 - val_loss: 0.3628 - val_accuracy: 0.8443\n",
            "Epoch 56/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3753 - accuracy: 0.8380 - val_loss: 0.3627 - val_accuracy: 0.8443\n",
            "Epoch 57/300\n",
            "102/102 [==============================] - 2s 15ms/step - loss: 0.3761 - accuracy: 0.8386 - val_loss: 0.3626 - val_accuracy: 0.8445\n",
            "Epoch 58/300\n",
            "102/102 [==============================] - 2s 19ms/step - loss: 0.3748 - accuracy: 0.8389 - val_loss: 0.3625 - val_accuracy: 0.8445\n",
            "Epoch 59/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3754 - accuracy: 0.8386 - val_loss: 0.3624 - val_accuracy: 0.8447\n",
            "Epoch 60/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3755 - accuracy: 0.8379 - val_loss: 0.3623 - val_accuracy: 0.8445\n",
            "Epoch 61/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3763 - accuracy: 0.8377 - val_loss: 0.3621 - val_accuracy: 0.8448\n",
            "Epoch 62/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3742 - accuracy: 0.8385 - val_loss: 0.3620 - val_accuracy: 0.8447\n",
            "Epoch 63/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3750 - accuracy: 0.8389 - val_loss: 0.3619 - val_accuracy: 0.8449\n",
            "Epoch 64/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3746 - accuracy: 0.8385 - val_loss: 0.3618 - val_accuracy: 0.8449\n",
            "Epoch 65/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3744 - accuracy: 0.8390 - val_loss: 0.3618 - val_accuracy: 0.8449\n",
            "Epoch 66/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3743 - accuracy: 0.8390 - val_loss: 0.3617 - val_accuracy: 0.8451\n",
            "Epoch 67/300\n",
            "102/102 [==============================] - 2s 16ms/step - loss: 0.3743 - accuracy: 0.8390 - val_loss: 0.3615 - val_accuracy: 0.8453\n",
            "Epoch 68/300\n",
            "102/102 [==============================] - 2s 19ms/step - loss: 0.3738 - accuracy: 0.8389 - val_loss: 0.3616 - val_accuracy: 0.8452\n",
            "Epoch 69/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3731 - accuracy: 0.8392 - val_loss: 0.3615 - val_accuracy: 0.8453\n",
            "Epoch 70/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3740 - accuracy: 0.8395 - val_loss: 0.3613 - val_accuracy: 0.8453\n",
            "Epoch 71/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3741 - accuracy: 0.8389 - val_loss: 0.3613 - val_accuracy: 0.8452\n",
            "Epoch 72/300\n",
            "102/102 [==============================] - 2s 19ms/step - loss: 0.3736 - accuracy: 0.8385 - val_loss: 0.3611 - val_accuracy: 0.8453\n",
            "Epoch 73/300\n",
            "102/102 [==============================] - 1s 14ms/step - loss: 0.3732 - accuracy: 0.8385 - val_loss: 0.3611 - val_accuracy: 0.8453\n",
            "Epoch 74/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3744 - accuracy: 0.8391 - val_loss: 0.3611 - val_accuracy: 0.8455\n",
            "Epoch 75/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3733 - accuracy: 0.8399 - val_loss: 0.3609 - val_accuracy: 0.8456\n",
            "Epoch 76/300\n",
            "102/102 [==============================] - 2s 16ms/step - loss: 0.3731 - accuracy: 0.8398 - val_loss: 0.3609 - val_accuracy: 0.8455\n",
            "Epoch 77/300\n",
            "102/102 [==============================] - 2s 23ms/step - loss: 0.3730 - accuracy: 0.8396 - val_loss: 0.3609 - val_accuracy: 0.8456\n",
            "Epoch 78/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3733 - accuracy: 0.8392 - val_loss: 0.3607 - val_accuracy: 0.8457\n",
            "Epoch 79/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3724 - accuracy: 0.8397 - val_loss: 0.3607 - val_accuracy: 0.8458\n",
            "Epoch 80/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3730 - accuracy: 0.8397 - val_loss: 0.3605 - val_accuracy: 0.8457\n",
            "Epoch 81/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3728 - accuracy: 0.8399 - val_loss: 0.3605 - val_accuracy: 0.8457\n",
            "Epoch 82/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3725 - accuracy: 0.8398 - val_loss: 0.3604 - val_accuracy: 0.8457\n",
            "Epoch 83/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3725 - accuracy: 0.8409 - val_loss: 0.3603 - val_accuracy: 0.8458\n",
            "Epoch 84/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3726 - accuracy: 0.8397 - val_loss: 0.3603 - val_accuracy: 0.8458\n",
            "Epoch 85/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3729 - accuracy: 0.8399 - val_loss: 0.3602 - val_accuracy: 0.8458\n",
            "Epoch 86/300\n",
            "102/102 [==============================] - 2s 16ms/step - loss: 0.3718 - accuracy: 0.8394 - val_loss: 0.3601 - val_accuracy: 0.8458\n",
            "Epoch 87/300\n",
            "102/102 [==============================] - 2s 17ms/step - loss: 0.3723 - accuracy: 0.8404 - val_loss: 0.3601 - val_accuracy: 0.8459\n",
            "Epoch 88/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3719 - accuracy: 0.8400 - val_loss: 0.3600 - val_accuracy: 0.8460\n",
            "Epoch 89/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3717 - accuracy: 0.8405 - val_loss: 0.3600 - val_accuracy: 0.8460\n",
            "Epoch 90/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3717 - accuracy: 0.8398 - val_loss: 0.3599 - val_accuracy: 0.8461\n",
            "Epoch 91/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3718 - accuracy: 0.8397 - val_loss: 0.3598 - val_accuracy: 0.8460\n",
            "Epoch 92/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3708 - accuracy: 0.8409 - val_loss: 0.3598 - val_accuracy: 0.8459\n",
            "Epoch 93/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3716 - accuracy: 0.8402 - val_loss: 0.3597 - val_accuracy: 0.8458\n",
            "Epoch 94/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3719 - accuracy: 0.8399 - val_loss: 0.3596 - val_accuracy: 0.8459\n",
            "Epoch 95/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3716 - accuracy: 0.8412 - val_loss: 0.3596 - val_accuracy: 0.8461\n",
            "Epoch 96/300\n",
            "102/102 [==============================] - 1s 15ms/step - loss: 0.3715 - accuracy: 0.8399 - val_loss: 0.3595 - val_accuracy: 0.8461\n",
            "Epoch 97/300\n",
            "102/102 [==============================] - 2s 19ms/step - loss: 0.3713 - accuracy: 0.8395 - val_loss: 0.3594 - val_accuracy: 0.8462\n",
            "Epoch 98/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3704 - accuracy: 0.8404 - val_loss: 0.3594 - val_accuracy: 0.8462\n",
            "Epoch 99/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3715 - accuracy: 0.8403 - val_loss: 0.3594 - val_accuracy: 0.8462\n",
            "Epoch 100/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3719 - accuracy: 0.8406 - val_loss: 0.3594 - val_accuracy: 0.8463\n",
            "Epoch 101/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3711 - accuracy: 0.8399 - val_loss: 0.3592 - val_accuracy: 0.8463\n",
            "Epoch 102/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3706 - accuracy: 0.8397 - val_loss: 0.3591 - val_accuracy: 0.8464\n",
            "Epoch 103/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3712 - accuracy: 0.8404 - val_loss: 0.3591 - val_accuracy: 0.8464\n",
            "Epoch 104/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3702 - accuracy: 0.8404 - val_loss: 0.3591 - val_accuracy: 0.8463\n",
            "Epoch 105/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3712 - accuracy: 0.8398 - val_loss: 0.3590 - val_accuracy: 0.8463\n",
            "Epoch 106/300\n",
            "102/102 [==============================] - 2s 16ms/step - loss: 0.3706 - accuracy: 0.8408 - val_loss: 0.3590 - val_accuracy: 0.8463\n",
            "Epoch 107/300\n",
            "102/102 [==============================] - 2s 19ms/step - loss: 0.3707 - accuracy: 0.8409 - val_loss: 0.3589 - val_accuracy: 0.8463\n",
            "Epoch 108/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3706 - accuracy: 0.8394 - val_loss: 0.3589 - val_accuracy: 0.8464\n",
            "Epoch 109/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3707 - accuracy: 0.8406 - val_loss: 0.3588 - val_accuracy: 0.8464\n",
            "Epoch 110/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3696 - accuracy: 0.8409 - val_loss: 0.3587 - val_accuracy: 0.8463\n",
            "Epoch 111/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3699 - accuracy: 0.8413 - val_loss: 0.3587 - val_accuracy: 0.8464\n",
            "Epoch 112/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3700 - accuracy: 0.8407 - val_loss: 0.3586 - val_accuracy: 0.8464\n",
            "Epoch 113/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3699 - accuracy: 0.8406 - val_loss: 0.3586 - val_accuracy: 0.8465\n",
            "Epoch 114/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3703 - accuracy: 0.8416 - val_loss: 0.3586 - val_accuracy: 0.8465\n",
            "Epoch 115/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3698 - accuracy: 0.8410 - val_loss: 0.3585 - val_accuracy: 0.8465\n",
            "Epoch 116/300\n",
            "102/102 [==============================] - 2s 17ms/step - loss: 0.3702 - accuracy: 0.8406 - val_loss: 0.3585 - val_accuracy: 0.8466\n",
            "Epoch 117/300\n",
            "102/102 [==============================] - 2s 17ms/step - loss: 0.3703 - accuracy: 0.8407 - val_loss: 0.3585 - val_accuracy: 0.8467\n",
            "Epoch 118/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3690 - accuracy: 0.8413 - val_loss: 0.3584 - val_accuracy: 0.8466\n",
            "Epoch 119/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3700 - accuracy: 0.8417 - val_loss: 0.3583 - val_accuracy: 0.8466\n",
            "Epoch 120/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3705 - accuracy: 0.8407 - val_loss: 0.3583 - val_accuracy: 0.8467\n",
            "Epoch 121/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3694 - accuracy: 0.8406 - val_loss: 0.3582 - val_accuracy: 0.8469\n",
            "Epoch 122/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3693 - accuracy: 0.8412 - val_loss: 0.3582 - val_accuracy: 0.8469\n",
            "Epoch 123/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3693 - accuracy: 0.8411 - val_loss: 0.3582 - val_accuracy: 0.8468\n",
            "Epoch 124/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3698 - accuracy: 0.8406 - val_loss: 0.3581 - val_accuracy: 0.8469\n",
            "Epoch 125/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3695 - accuracy: 0.8412 - val_loss: 0.3581 - val_accuracy: 0.8469\n",
            "Epoch 126/300\n",
            "102/102 [==============================] - 2s 15ms/step - loss: 0.3692 - accuracy: 0.8408 - val_loss: 0.3580 - val_accuracy: 0.8470\n",
            "Epoch 127/300\n",
            "102/102 [==============================] - 2s 19ms/step - loss: 0.3694 - accuracy: 0.8413 - val_loss: 0.3580 - val_accuracy: 0.8469\n",
            "Epoch 128/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3692 - accuracy: 0.8413 - val_loss: 0.3579 - val_accuracy: 0.8471\n",
            "Epoch 129/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3685 - accuracy: 0.8419 - val_loss: 0.3579 - val_accuracy: 0.8471\n",
            "Epoch 130/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3693 - accuracy: 0.8408 - val_loss: 0.3578 - val_accuracy: 0.8471\n",
            "Epoch 131/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3696 - accuracy: 0.8412 - val_loss: 0.3578 - val_accuracy: 0.8470\n",
            "Epoch 132/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3693 - accuracy: 0.8411 - val_loss: 0.3578 - val_accuracy: 0.8472\n",
            "Epoch 133/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3689 - accuracy: 0.8418 - val_loss: 0.3578 - val_accuracy: 0.8470\n",
            "Epoch 134/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3693 - accuracy: 0.8412 - val_loss: 0.3577 - val_accuracy: 0.8471\n",
            "Epoch 135/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3685 - accuracy: 0.8406 - val_loss: 0.3576 - val_accuracy: 0.8472\n",
            "Epoch 136/300\n",
            "102/102 [==============================] - 2s 17ms/step - loss: 0.3689 - accuracy: 0.8409 - val_loss: 0.3576 - val_accuracy: 0.8472\n",
            "Epoch 137/300\n",
            "102/102 [==============================] - 2s 17ms/step - loss: 0.3690 - accuracy: 0.8415 - val_loss: 0.3575 - val_accuracy: 0.8474\n",
            "Epoch 138/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3692 - accuracy: 0.8407 - val_loss: 0.3575 - val_accuracy: 0.8475\n",
            "Epoch 139/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3693 - accuracy: 0.8411 - val_loss: 0.3575 - val_accuracy: 0.8473\n",
            "Epoch 140/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3692 - accuracy: 0.8413 - val_loss: 0.3575 - val_accuracy: 0.8474\n",
            "Epoch 141/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3683 - accuracy: 0.8408 - val_loss: 0.3574 - val_accuracy: 0.8473\n",
            "Epoch 142/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3679 - accuracy: 0.8414 - val_loss: 0.3574 - val_accuracy: 0.8474\n",
            "Epoch 143/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3683 - accuracy: 0.8418 - val_loss: 0.3574 - val_accuracy: 0.8473\n",
            "Epoch 144/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3680 - accuracy: 0.8408 - val_loss: 0.3573 - val_accuracy: 0.8474\n",
            "Epoch 145/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3684 - accuracy: 0.8411 - val_loss: 0.3573 - val_accuracy: 0.8474\n",
            "Epoch 146/300\n",
            "102/102 [==============================] - 2s 17ms/step - loss: 0.3687 - accuracy: 0.8411 - val_loss: 0.3573 - val_accuracy: 0.8474\n",
            "Epoch 147/300\n",
            "102/102 [==============================] - 3s 25ms/step - loss: 0.3684 - accuracy: 0.8417 - val_loss: 0.3572 - val_accuracy: 0.8475\n",
            "Epoch 148/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3683 - accuracy: 0.8415 - val_loss: 0.3571 - val_accuracy: 0.8475\n",
            "Epoch 149/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3686 - accuracy: 0.8420 - val_loss: 0.3571 - val_accuracy: 0.8475\n",
            "Epoch 150/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3679 - accuracy: 0.8419 - val_loss: 0.3571 - val_accuracy: 0.8476\n",
            "Epoch 151/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3681 - accuracy: 0.8417 - val_loss: 0.3570 - val_accuracy: 0.8476\n",
            "Epoch 152/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3678 - accuracy: 0.8415 - val_loss: 0.3570 - val_accuracy: 0.8476\n",
            "Epoch 153/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3682 - accuracy: 0.8413 - val_loss: 0.3570 - val_accuracy: 0.8476\n",
            "Epoch 154/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3680 - accuracy: 0.8412 - val_loss: 0.3570 - val_accuracy: 0.8476\n",
            "Epoch 155/300\n",
            "102/102 [==============================] - 1s 13ms/step - loss: 0.3678 - accuracy: 0.8416 - val_loss: 0.3569 - val_accuracy: 0.8476\n",
            "Epoch 156/300\n",
            "102/102 [==============================] - 2s 18ms/step - loss: 0.3673 - accuracy: 0.8422 - val_loss: 0.3569 - val_accuracy: 0.8477\n",
            "Epoch 157/300\n",
            "102/102 [==============================] - 1s 14ms/step - loss: 0.3677 - accuracy: 0.8417 - val_loss: 0.3569 - val_accuracy: 0.8477\n",
            "Epoch 158/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3683 - accuracy: 0.8414 - val_loss: 0.3568 - val_accuracy: 0.8478\n",
            "Epoch 159/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3670 - accuracy: 0.8424 - val_loss: 0.3567 - val_accuracy: 0.8478\n",
            "Epoch 160/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3675 - accuracy: 0.8422 - val_loss: 0.3567 - val_accuracy: 0.8477\n",
            "Epoch 161/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3673 - accuracy: 0.8417 - val_loss: 0.3567 - val_accuracy: 0.8478\n",
            "Epoch 162/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3678 - accuracy: 0.8415 - val_loss: 0.3567 - val_accuracy: 0.8477\n",
            "Epoch 163/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3679 - accuracy: 0.8417 - val_loss: 0.3566 - val_accuracy: 0.8479\n",
            "Epoch 164/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3672 - accuracy: 0.8422 - val_loss: 0.3565 - val_accuracy: 0.8478\n",
            "Epoch 165/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3671 - accuracy: 0.8425 - val_loss: 0.3566 - val_accuracy: 0.8477\n",
            "Epoch 166/300\n",
            "102/102 [==============================] - 2s 18ms/step - loss: 0.3666 - accuracy: 0.8423 - val_loss: 0.3565 - val_accuracy: 0.8477\n",
            "Epoch 167/300\n",
            "102/102 [==============================] - 2s 15ms/step - loss: 0.3669 - accuracy: 0.8413 - val_loss: 0.3565 - val_accuracy: 0.8476\n",
            "Epoch 168/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3672 - accuracy: 0.8421 - val_loss: 0.3565 - val_accuracy: 0.8479\n",
            "Epoch 169/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3666 - accuracy: 0.8422 - val_loss: 0.3564 - val_accuracy: 0.8477\n",
            "Epoch 170/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3666 - accuracy: 0.8423 - val_loss: 0.3564 - val_accuracy: 0.8477\n",
            "Epoch 171/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3673 - accuracy: 0.8412 - val_loss: 0.3564 - val_accuracy: 0.8478\n",
            "Epoch 172/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3671 - accuracy: 0.8423 - val_loss: 0.3563 - val_accuracy: 0.8479\n",
            "Epoch 173/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3669 - accuracy: 0.8429 - val_loss: 0.3563 - val_accuracy: 0.8480\n",
            "Epoch 174/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3667 - accuracy: 0.8418 - val_loss: 0.3562 - val_accuracy: 0.8479\n",
            "Epoch 175/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3668 - accuracy: 0.8423 - val_loss: 0.3562 - val_accuracy: 0.8477\n",
            "Epoch 176/300\n",
            "102/102 [==============================] - 2s 18ms/step - loss: 0.3670 - accuracy: 0.8425 - val_loss: 0.3563 - val_accuracy: 0.8478\n",
            "Epoch 177/300\n",
            "102/102 [==============================] - 2s 15ms/step - loss: 0.3670 - accuracy: 0.8420 - val_loss: 0.3562 - val_accuracy: 0.8480\n",
            "Epoch 178/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3670 - accuracy: 0.8414 - val_loss: 0.3561 - val_accuracy: 0.8481\n",
            "Epoch 179/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3667 - accuracy: 0.8425 - val_loss: 0.3561 - val_accuracy: 0.8480\n",
            "Epoch 180/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3669 - accuracy: 0.8414 - val_loss: 0.3561 - val_accuracy: 0.8480\n",
            "Epoch 181/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3667 - accuracy: 0.8418 - val_loss: 0.3560 - val_accuracy: 0.8480\n",
            "Epoch 182/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3664 - accuracy: 0.8416 - val_loss: 0.3560 - val_accuracy: 0.8480\n",
            "Epoch 183/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3667 - accuracy: 0.8425 - val_loss: 0.3560 - val_accuracy: 0.8481\n",
            "Epoch 184/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3659 - accuracy: 0.8426 - val_loss: 0.3559 - val_accuracy: 0.8481\n",
            "Epoch 185/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3668 - accuracy: 0.8412 - val_loss: 0.3559 - val_accuracy: 0.8480\n",
            "Epoch 186/300\n",
            "102/102 [==============================] - 2s 18ms/step - loss: 0.3669 - accuracy: 0.8420 - val_loss: 0.3559 - val_accuracy: 0.8479\n",
            "Epoch 187/300\n",
            "102/102 [==============================] - 2s 16ms/step - loss: 0.3665 - accuracy: 0.8424 - val_loss: 0.3559 - val_accuracy: 0.8478\n",
            "Epoch 188/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3662 - accuracy: 0.8421 - val_loss: 0.3558 - val_accuracy: 0.8479\n",
            "Epoch 189/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3665 - accuracy: 0.8419 - val_loss: 0.3559 - val_accuracy: 0.8480\n",
            "Epoch 190/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3660 - accuracy: 0.8419 - val_loss: 0.3558 - val_accuracy: 0.8480\n",
            "Epoch 191/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3662 - accuracy: 0.8421 - val_loss: 0.3558 - val_accuracy: 0.8479\n",
            "Epoch 192/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3669 - accuracy: 0.8416 - val_loss: 0.3557 - val_accuracy: 0.8479\n",
            "Epoch 193/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3660 - accuracy: 0.8421 - val_loss: 0.3556 - val_accuracy: 0.8480\n",
            "Epoch 194/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3657 - accuracy: 0.8422 - val_loss: 0.3557 - val_accuracy: 0.8480\n",
            "Epoch 195/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3667 - accuracy: 0.8417 - val_loss: 0.3556 - val_accuracy: 0.8480\n",
            "Epoch 196/300\n",
            "102/102 [==============================] - 2s 17ms/step - loss: 0.3653 - accuracy: 0.8433 - val_loss: 0.3556 - val_accuracy: 0.8480\n",
            "Epoch 197/300\n",
            "102/102 [==============================] - 2s 17ms/step - loss: 0.3650 - accuracy: 0.8430 - val_loss: 0.3555 - val_accuracy: 0.8480\n",
            "Epoch 198/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3657 - accuracy: 0.8426 - val_loss: 0.3555 - val_accuracy: 0.8480\n",
            "Epoch 199/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3664 - accuracy: 0.8427 - val_loss: 0.3555 - val_accuracy: 0.8480\n",
            "Epoch 200/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3657 - accuracy: 0.8429 - val_loss: 0.3555 - val_accuracy: 0.8482\n",
            "Epoch 201/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3656 - accuracy: 0.8426 - val_loss: 0.3555 - val_accuracy: 0.8482\n",
            "Epoch 202/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3661 - accuracy: 0.8422 - val_loss: 0.3554 - val_accuracy: 0.8481\n",
            "Epoch 203/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3658 - accuracy: 0.8418 - val_loss: 0.3554 - val_accuracy: 0.8481\n",
            "Epoch 204/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3662 - accuracy: 0.8420 - val_loss: 0.3554 - val_accuracy: 0.8481\n",
            "Epoch 205/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3651 - accuracy: 0.8423 - val_loss: 0.3553 - val_accuracy: 0.8481\n",
            "Epoch 206/300\n",
            "102/102 [==============================] - 1s 14ms/step - loss: 0.3653 - accuracy: 0.8427 - val_loss: 0.3553 - val_accuracy: 0.8482\n",
            "Epoch 207/300\n",
            "102/102 [==============================] - 2s 18ms/step - loss: 0.3655 - accuracy: 0.8427 - val_loss: 0.3553 - val_accuracy: 0.8480\n",
            "Epoch 208/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3659 - accuracy: 0.8425 - val_loss: 0.3553 - val_accuracy: 0.8481\n",
            "Epoch 209/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3655 - accuracy: 0.8425 - val_loss: 0.3552 - val_accuracy: 0.8481\n",
            "Epoch 210/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3655 - accuracy: 0.8419 - val_loss: 0.3552 - val_accuracy: 0.8482\n",
            "Epoch 211/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3663 - accuracy: 0.8425 - val_loss: 0.3552 - val_accuracy: 0.8481\n",
            "Epoch 212/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3655 - accuracy: 0.8423 - val_loss: 0.3552 - val_accuracy: 0.8481\n",
            "Epoch 213/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3651 - accuracy: 0.8427 - val_loss: 0.3551 - val_accuracy: 0.8482\n",
            "Epoch 214/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3648 - accuracy: 0.8432 - val_loss: 0.3551 - val_accuracy: 0.8481\n",
            "Epoch 215/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3647 - accuracy: 0.8429 - val_loss: 0.3551 - val_accuracy: 0.8481\n",
            "Epoch 216/300\n",
            "102/102 [==============================] - 2s 15ms/step - loss: 0.3651 - accuracy: 0.8432 - val_loss: 0.3551 - val_accuracy: 0.8481\n",
            "Epoch 217/300\n",
            "102/102 [==============================] - 2s 18ms/step - loss: 0.3657 - accuracy: 0.8424 - val_loss: 0.3551 - val_accuracy: 0.8482\n",
            "Epoch 218/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3655 - accuracy: 0.8423 - val_loss: 0.3550 - val_accuracy: 0.8482\n",
            "Epoch 219/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3653 - accuracy: 0.8431 - val_loss: 0.3550 - val_accuracy: 0.8482\n",
            "Epoch 220/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3658 - accuracy: 0.8427 - val_loss: 0.3549 - val_accuracy: 0.8482\n",
            "Epoch 221/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3648 - accuracy: 0.8437 - val_loss: 0.3549 - val_accuracy: 0.8482\n",
            "Epoch 222/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3652 - accuracy: 0.8430 - val_loss: 0.3549 - val_accuracy: 0.8482\n",
            "Epoch 223/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3656 - accuracy: 0.8424 - val_loss: 0.3549 - val_accuracy: 0.8482\n",
            "Epoch 224/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3658 - accuracy: 0.8428 - val_loss: 0.3549 - val_accuracy: 0.8483\n",
            "Epoch 225/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3647 - accuracy: 0.8437 - val_loss: 0.3548 - val_accuracy: 0.8481\n",
            "Epoch 226/300\n",
            "102/102 [==============================] - 1s 14ms/step - loss: 0.3649 - accuracy: 0.8433 - val_loss: 0.3548 - val_accuracy: 0.8483\n",
            "Epoch 227/300\n",
            "102/102 [==============================] - 2s 17ms/step - loss: 0.3645 - accuracy: 0.8427 - val_loss: 0.3548 - val_accuracy: 0.8482\n",
            "Epoch 228/300\n",
            "102/102 [==============================] - 1s 14ms/step - loss: 0.3652 - accuracy: 0.8429 - val_loss: 0.3547 - val_accuracy: 0.8482\n",
            "Epoch 229/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3652 - accuracy: 0.8432 - val_loss: 0.3547 - val_accuracy: 0.8483\n",
            "Epoch 230/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3648 - accuracy: 0.8422 - val_loss: 0.3547 - val_accuracy: 0.8482\n",
            "Epoch 231/300\n",
            "102/102 [==============================] - 2s 17ms/step - loss: 0.3648 - accuracy: 0.8428 - val_loss: 0.3547 - val_accuracy: 0.8483\n",
            "Epoch 232/300\n",
            "102/102 [==============================] - 2s 18ms/step - loss: 0.3647 - accuracy: 0.8429 - val_loss: 0.3546 - val_accuracy: 0.8482\n",
            "Epoch 233/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3645 - accuracy: 0.8435 - val_loss: 0.3546 - val_accuracy: 0.8482\n",
            "Epoch 234/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3643 - accuracy: 0.8432 - val_loss: 0.3546 - val_accuracy: 0.8485\n",
            "Epoch 235/300\n",
            "102/102 [==============================] - 1s 14ms/step - loss: 0.3645 - accuracy: 0.8436 - val_loss: 0.3546 - val_accuracy: 0.8484\n",
            "Epoch 236/300\n",
            "102/102 [==============================] - 2s 17ms/step - loss: 0.3652 - accuracy: 0.8427 - val_loss: 0.3546 - val_accuracy: 0.8484\n",
            "Epoch 237/300\n",
            "102/102 [==============================] - 2s 15ms/step - loss: 0.3648 - accuracy: 0.8433 - val_loss: 0.3545 - val_accuracy: 0.8484\n",
            "Epoch 238/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3647 - accuracy: 0.8432 - val_loss: 0.3545 - val_accuracy: 0.8484\n",
            "Epoch 239/300\n",
            "102/102 [==============================] - 1s 11ms/step - loss: 0.3649 - accuracy: 0.8426 - val_loss: 0.3545 - val_accuracy: 0.8483\n",
            "Epoch 240/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3641 - accuracy: 0.8434 - val_loss: 0.3544 - val_accuracy: 0.8484\n",
            "Epoch 241/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3639 - accuracy: 0.8431 - val_loss: 0.3545 - val_accuracy: 0.8485\n",
            "Epoch 242/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3643 - accuracy: 0.8433 - val_loss: 0.3544 - val_accuracy: 0.8483\n",
            "Epoch 243/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3652 - accuracy: 0.8428 - val_loss: 0.3544 - val_accuracy: 0.8484\n",
            "Epoch 244/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3646 - accuracy: 0.8434 - val_loss: 0.3544 - val_accuracy: 0.8484\n",
            "Epoch 245/300\n",
            "102/102 [==============================] - 1s 14ms/step - loss: 0.3636 - accuracy: 0.8437 - val_loss: 0.3543 - val_accuracy: 0.8483\n",
            "Epoch 246/300\n",
            "102/102 [==============================] - 2s 19ms/step - loss: 0.3646 - accuracy: 0.8432 - val_loss: 0.3544 - val_accuracy: 0.8484\n",
            "Epoch 247/300\n",
            "102/102 [==============================] - 1s 14ms/step - loss: 0.3644 - accuracy: 0.8424 - val_loss: 0.3543 - val_accuracy: 0.8483\n",
            "Epoch 248/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3647 - accuracy: 0.8436 - val_loss: 0.3543 - val_accuracy: 0.8484\n",
            "Epoch 249/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3649 - accuracy: 0.8420 - val_loss: 0.3543 - val_accuracy: 0.8484\n",
            "Epoch 250/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3647 - accuracy: 0.8429 - val_loss: 0.3542 - val_accuracy: 0.8484\n",
            "Epoch 251/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3639 - accuracy: 0.8427 - val_loss: 0.3542 - val_accuracy: 0.8485\n",
            "Epoch 252/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3638 - accuracy: 0.8432 - val_loss: 0.3542 - val_accuracy: 0.8485\n",
            "Epoch 253/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3637 - accuracy: 0.8432 - val_loss: 0.3542 - val_accuracy: 0.8485\n",
            "Epoch 254/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3638 - accuracy: 0.8433 - val_loss: 0.3542 - val_accuracy: 0.8485\n",
            "Epoch 255/300\n",
            "102/102 [==============================] - 1s 15ms/step - loss: 0.3639 - accuracy: 0.8434 - val_loss: 0.3541 - val_accuracy: 0.8485\n",
            "Epoch 256/300\n",
            "102/102 [==============================] - 2s 18ms/step - loss: 0.3634 - accuracy: 0.8434 - val_loss: 0.3541 - val_accuracy: 0.8486\n",
            "Epoch 257/300\n",
            "102/102 [==============================] - 1s 14ms/step - loss: 0.3639 - accuracy: 0.8439 - val_loss: 0.3541 - val_accuracy: 0.8486\n",
            "Epoch 258/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3647 - accuracy: 0.8432 - val_loss: 0.3540 - val_accuracy: 0.8487\n",
            "Epoch 259/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3638 - accuracy: 0.8440 - val_loss: 0.3540 - val_accuracy: 0.8487\n",
            "Epoch 260/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3641 - accuracy: 0.8432 - val_loss: 0.3540 - val_accuracy: 0.8487\n",
            "Epoch 261/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3644 - accuracy: 0.8428 - val_loss: 0.3540 - val_accuracy: 0.8487\n",
            "Epoch 262/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3637 - accuracy: 0.8434 - val_loss: 0.3540 - val_accuracy: 0.8487\n",
            "Epoch 263/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3641 - accuracy: 0.8435 - val_loss: 0.3539 - val_accuracy: 0.8486\n",
            "Epoch 264/300\n",
            "102/102 [==============================] - 1s 13ms/step - loss: 0.3642 - accuracy: 0.8431 - val_loss: 0.3540 - val_accuracy: 0.8487\n",
            "Epoch 265/300\n",
            "102/102 [==============================] - 2s 16ms/step - loss: 0.3641 - accuracy: 0.8431 - val_loss: 0.3539 - val_accuracy: 0.8486\n",
            "Epoch 266/300\n",
            "102/102 [==============================] - 2s 18ms/step - loss: 0.3637 - accuracy: 0.8430 - val_loss: 0.3539 - val_accuracy: 0.8486\n",
            "Epoch 267/300\n",
            "102/102 [==============================] - 1s 13ms/step - loss: 0.3643 - accuracy: 0.8439 - val_loss: 0.3539 - val_accuracy: 0.8487\n",
            "Epoch 268/300\n",
            "102/102 [==============================] - 1s 13ms/step - loss: 0.3644 - accuracy: 0.8436 - val_loss: 0.3539 - val_accuracy: 0.8487\n",
            "Epoch 269/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3641 - accuracy: 0.8433 - val_loss: 0.3539 - val_accuracy: 0.8486\n",
            "Epoch 270/300\n",
            "102/102 [==============================] - 1s 13ms/step - loss: 0.3637 - accuracy: 0.8435 - val_loss: 0.3538 - val_accuracy: 0.8485\n",
            "Epoch 271/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3639 - accuracy: 0.8433 - val_loss: 0.3538 - val_accuracy: 0.8486\n",
            "Epoch 272/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3637 - accuracy: 0.8434 - val_loss: 0.3538 - val_accuracy: 0.8486\n",
            "Epoch 273/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3633 - accuracy: 0.8437 - val_loss: 0.3537 - val_accuracy: 0.8486\n",
            "Epoch 274/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3635 - accuracy: 0.8436 - val_loss: 0.3537 - val_accuracy: 0.8485\n",
            "Epoch 275/300\n",
            "102/102 [==============================] - 2s 19ms/step - loss: 0.3634 - accuracy: 0.8435 - val_loss: 0.3537 - val_accuracy: 0.8485\n",
            "Epoch 276/300\n",
            "102/102 [==============================] - 2s 17ms/step - loss: 0.3630 - accuracy: 0.8438 - val_loss: 0.3537 - val_accuracy: 0.8486\n",
            "Epoch 277/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3631 - accuracy: 0.8440 - val_loss: 0.3536 - val_accuracy: 0.8487\n",
            "Epoch 278/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3634 - accuracy: 0.8432 - val_loss: 0.3537 - val_accuracy: 0.8486\n",
            "Epoch 279/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3632 - accuracy: 0.8437 - val_loss: 0.3537 - val_accuracy: 0.8487\n",
            "Epoch 280/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3637 - accuracy: 0.8438 - val_loss: 0.3536 - val_accuracy: 0.8487\n",
            "Epoch 281/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3639 - accuracy: 0.8432 - val_loss: 0.3536 - val_accuracy: 0.8488\n",
            "Epoch 282/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3635 - accuracy: 0.8431 - val_loss: 0.3536 - val_accuracy: 0.8487\n",
            "Epoch 283/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3632 - accuracy: 0.8440 - val_loss: 0.3535 - val_accuracy: 0.8488\n",
            "Epoch 284/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3629 - accuracy: 0.8438 - val_loss: 0.3535 - val_accuracy: 0.8488\n",
            "Epoch 285/300\n",
            "102/102 [==============================] - 2s 18ms/step - loss: 0.3628 - accuracy: 0.8442 - val_loss: 0.3535 - val_accuracy: 0.8488\n",
            "Epoch 286/300\n",
            "102/102 [==============================] - 2s 16ms/step - loss: 0.3634 - accuracy: 0.8440 - val_loss: 0.3535 - val_accuracy: 0.8488\n",
            "Epoch 287/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3634 - accuracy: 0.8434 - val_loss: 0.3535 - val_accuracy: 0.8488\n",
            "Epoch 288/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3633 - accuracy: 0.8433 - val_loss: 0.3534 - val_accuracy: 0.8488\n",
            "Epoch 289/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3637 - accuracy: 0.8437 - val_loss: 0.3534 - val_accuracy: 0.8489\n",
            "Epoch 290/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3633 - accuracy: 0.8434 - val_loss: 0.3534 - val_accuracy: 0.8488\n",
            "Epoch 291/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3631 - accuracy: 0.8438 - val_loss: 0.3534 - val_accuracy: 0.8488\n",
            "Epoch 292/300\n",
            "102/102 [==============================] - 1s 13ms/step - loss: 0.3629 - accuracy: 0.8437 - val_loss: 0.3533 - val_accuracy: 0.8490\n",
            "Epoch 293/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3631 - accuracy: 0.8427 - val_loss: 0.3533 - val_accuracy: 0.8487\n",
            "Epoch 294/300\n",
            "102/102 [==============================] - 1s 14ms/step - loss: 0.3629 - accuracy: 0.8441 - val_loss: 0.3533 - val_accuracy: 0.8488\n",
            "Epoch 295/300\n",
            "102/102 [==============================] - 2s 19ms/step - loss: 0.3633 - accuracy: 0.8430 - val_loss: 0.3533 - val_accuracy: 0.8489\n",
            "Epoch 296/300\n",
            "102/102 [==============================] - 1s 14ms/step - loss: 0.3635 - accuracy: 0.8430 - val_loss: 0.3533 - val_accuracy: 0.8489\n",
            "Epoch 297/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3634 - accuracy: 0.8438 - val_loss: 0.3533 - val_accuracy: 0.8488\n",
            "Epoch 298/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3633 - accuracy: 0.8434 - val_loss: 0.3532 - val_accuracy: 0.8488\n",
            "Epoch 299/300\n",
            "102/102 [==============================] - 1s 13ms/step - loss: 0.3631 - accuracy: 0.8440 - val_loss: 0.3532 - val_accuracy: 0.8489\n",
            "Epoch 300/300\n",
            "102/102 [==============================] - 1s 12ms/step - loss: 0.3626 - accuracy: 0.8444 - val_loss: 0.3532 - val_accuracy: 0.8490\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f68e749bf10>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ann.history.history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp_l5sVdlBSE",
        "outputId": "30c26865-1084-40af-9d08-c8c5b8e6bd6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [0.5337765216827393,\n",
              "  0.4715084433555603,\n",
              "  0.4404360353946686,\n",
              "  0.4235411584377289,\n",
              "  0.41352951526641846,\n",
              "  0.4071599543094635,\n",
              "  0.4030168354511261,\n",
              "  0.4004335105419159,\n",
              "  0.39745432138442993,\n",
              "  0.39497822523117065,\n",
              "  0.3944602310657501,\n",
              "  0.39223888516426086,\n",
              "  0.3911304771900177,\n",
              "  0.39041438698768616,\n",
              "  0.3902706503868103,\n",
              "  0.38759925961494446,\n",
              "  0.3879943788051605,\n",
              "  0.3866078853607178,\n",
              "  0.3861214816570282,\n",
              "  0.3854904770851135,\n",
              "  0.3854711949825287,\n",
              "  0.3852497339248657,\n",
              "  0.3846254348754883,\n",
              "  0.3834248483181,\n",
              "  0.38319867849349976,\n",
              "  0.382927268743515,\n",
              "  0.382790744304657,\n",
              "  0.3826231360435486,\n",
              "  0.3819969594478607,\n",
              "  0.3807067275047302,\n",
              "  0.38109293580055237,\n",
              "  0.38050365447998047,\n",
              "  0.38066524267196655,\n",
              "  0.3801833689212799,\n",
              "  0.37990984320640564,\n",
              "  0.3799642324447632,\n",
              "  0.3799948990345001,\n",
              "  0.3792836666107178,\n",
              "  0.37904050946235657,\n",
              "  0.3785269558429718,\n",
              "  0.3795078694820404,\n",
              "  0.37821558117866516,\n",
              "  0.3781466484069824,\n",
              "  0.3786952793598175,\n",
              "  0.37843671441078186,\n",
              "  0.37776607275009155,\n",
              "  0.37709343433380127,\n",
              "  0.37747320532798767,\n",
              "  0.37637758255004883,\n",
              "  0.3771699070930481,\n",
              "  0.3767375946044922,\n",
              "  0.3774949610233307,\n",
              "  0.37555497884750366,\n",
              "  0.3767766058444977,\n",
              "  0.37582260370254517,\n",
              "  0.37531396746635437,\n",
              "  0.376103013753891,\n",
              "  0.37480905652046204,\n",
              "  0.3753533959388733,\n",
              "  0.3754509687423706,\n",
              "  0.37626802921295166,\n",
              "  0.3742080628871918,\n",
              "  0.3750024437904358,\n",
              "  0.3746362030506134,\n",
              "  0.3744211792945862,\n",
              "  0.37429410219192505,\n",
              "  0.37425386905670166,\n",
              "  0.37384694814682007,\n",
              "  0.3731248378753662,\n",
              "  0.3740209639072418,\n",
              "  0.3741146922111511,\n",
              "  0.37361621856689453,\n",
              "  0.37315839529037476,\n",
              "  0.3743972182273865,\n",
              "  0.37331458926200867,\n",
              "  0.37313491106033325,\n",
              "  0.37297847867012024,\n",
              "  0.37329620122909546,\n",
              "  0.37241390347480774,\n",
              "  0.3729989528656006,\n",
              "  0.37280920147895813,\n",
              "  0.37246251106262207,\n",
              "  0.37250545620918274,\n",
              "  0.3726148009300232,\n",
              "  0.3729201555252075,\n",
              "  0.37182727456092834,\n",
              "  0.3723352253437042,\n",
              "  0.3719421327114105,\n",
              "  0.3716762959957123,\n",
              "  0.37167680263519287,\n",
              "  0.37180036306381226,\n",
              "  0.3708469569683075,\n",
              "  0.37158238887786865,\n",
              "  0.37192225456237793,\n",
              "  0.3716370165348053,\n",
              "  0.3715079128742218,\n",
              "  0.3712631165981293,\n",
              "  0.3703667223453522,\n",
              "  0.3714977204799652,\n",
              "  0.37185296416282654,\n",
              "  0.3710632622241974,\n",
              "  0.370582640171051,\n",
              "  0.37115541100502014,\n",
              "  0.3702189326286316,\n",
              "  0.3712207078933716,\n",
              "  0.37062111496925354,\n",
              "  0.3707374930381775,\n",
              "  0.37061095237731934,\n",
              "  0.37065500020980835,\n",
              "  0.36958587169647217,\n",
              "  0.3698790967464447,\n",
              "  0.369985431432724,\n",
              "  0.36994031071662903,\n",
              "  0.37033718824386597,\n",
              "  0.3698415756225586,\n",
              "  0.3701593577861786,\n",
              "  0.37030813097953796,\n",
              "  0.36904630064964294,\n",
              "  0.3699735701084137,\n",
              "  0.3704989552497864,\n",
              "  0.3693564236164093,\n",
              "  0.3693372905254364,\n",
              "  0.3692921996116638,\n",
              "  0.3698258399963379,\n",
              "  0.36952534317970276,\n",
              "  0.3691882789134979,\n",
              "  0.36939024925231934,\n",
              "  0.36917856335639954,\n",
              "  0.3684585690498352,\n",
              "  0.3692808151245117,\n",
              "  0.36962223052978516,\n",
              "  0.3693210780620575,\n",
              "  0.3689000606536865,\n",
              "  0.36931145191192627,\n",
              "  0.3685384690761566,\n",
              "  0.368941068649292,\n",
              "  0.36900416016578674,\n",
              "  0.3691766858100891,\n",
              "  0.36928462982177734,\n",
              "  0.36917611956596375,\n",
              "  0.368306040763855,\n",
              "  0.3679251968860626,\n",
              "  0.36831262707710266,\n",
              "  0.36802539229393005,\n",
              "  0.36843326687812805,\n",
              "  0.3686574399471283,\n",
              "  0.3683924973011017,\n",
              "  0.36832356452941895,\n",
              "  0.3686293661594391,\n",
              "  0.36785081028938293,\n",
              "  0.36811593174934387,\n",
              "  0.3677743077278137,\n",
              "  0.3682350218296051,\n",
              "  0.36795130372047424,\n",
              "  0.36782196164131165,\n",
              "  0.36732327938079834,\n",
              "  0.36774715781211853,\n",
              "  0.36825764179229736,\n",
              "  0.36696353554725647,\n",
              "  0.3675440549850464,\n",
              "  0.36733120679855347,\n",
              "  0.3677694797515869,\n",
              "  0.367929071187973,\n",
              "  0.3672235608100891,\n",
              "  0.3671262860298157,\n",
              "  0.3665923774242401,\n",
              "  0.3669128119945526,\n",
              "  0.36716243624687195,\n",
              "  0.36664167046546936,\n",
              "  0.3666166067123413,\n",
              "  0.36726218461990356,\n",
              "  0.3671075105667114,\n",
              "  0.36693814396858215,\n",
              "  0.3666757345199585,\n",
              "  0.36677560210227966,\n",
              "  0.36698606610298157,\n",
              "  0.3670124411582947,\n",
              "  0.36696645617485046,\n",
              "  0.3667065501213074,\n",
              "  0.3669227659702301,\n",
              "  0.36670929193496704,\n",
              "  0.36640915274620056,\n",
              "  0.36667752265930176,\n",
              "  0.3659417927265167,\n",
              "  0.36675816774368286,\n",
              "  0.36689314246177673,\n",
              "  0.3665415346622467,\n",
              "  0.3661562204360962,\n",
              "  0.3665008246898651,\n",
              "  0.3660423755645752,\n",
              "  0.3661592900753021,\n",
              "  0.36688244342803955,\n",
              "  0.3659655451774597,\n",
              "  0.3656984567642212,\n",
              "  0.3667317032814026,\n",
              "  0.3652811646461487,\n",
              "  0.36504408717155457,\n",
              "  0.36572742462158203,\n",
              "  0.36642223596572876,\n",
              "  0.36571982502937317,\n",
              "  0.36564934253692627,\n",
              "  0.3660714626312256,\n",
              "  0.36580890417099,\n",
              "  0.3661666810512543,\n",
              "  0.3651353120803833,\n",
              "  0.36529776453971863,\n",
              "  0.3655374050140381,\n",
              "  0.3659276068210602,\n",
              "  0.36546623706817627,\n",
              "  0.36554422974586487,\n",
              "  0.3663063645362854,\n",
              "  0.36549413204193115,\n",
              "  0.3651023805141449,\n",
              "  0.36477547883987427,\n",
              "  0.3647427558898926,\n",
              "  0.3651304543018341,\n",
              "  0.36570674180984497,\n",
              "  0.365539014339447,\n",
              "  0.36530277132987976,\n",
              "  0.3658113181591034,\n",
              "  0.364839106798172,\n",
              "  0.36518198251724243,\n",
              "  0.3656473457813263,\n",
              "  0.36582326889038086,\n",
              "  0.36470967531204224,\n",
              "  0.3649200201034546,\n",
              "  0.36451441049575806,\n",
              "  0.3652486801147461,\n",
              "  0.36521291732788086,\n",
              "  0.3647648096084595,\n",
              "  0.36484014987945557,\n",
              "  0.36472198367118835,\n",
              "  0.36445367336273193,\n",
              "  0.3642924427986145,\n",
              "  0.36446595191955566,\n",
              "  0.3651629388332367,\n",
              "  0.36477988958358765,\n",
              "  0.3647494316101074,\n",
              "  0.36488234996795654,\n",
              "  0.3640971779823303,\n",
              "  0.3638840317726135,\n",
              "  0.3642931580543518,\n",
              "  0.3652264475822449,\n",
              "  0.3645717203617096,\n",
              "  0.3635818660259247,\n",
              "  0.36459827423095703,\n",
              "  0.3644244968891144,\n",
              "  0.3646673262119293,\n",
              "  0.36491209268569946,\n",
              "  0.36472824215888977,\n",
              "  0.3639242351055145,\n",
              "  0.3637537360191345,\n",
              "  0.36374661326408386,\n",
              "  0.3637657165527344,\n",
              "  0.36390963196754456,\n",
              "  0.36344099044799805,\n",
              "  0.3638521432876587,\n",
              "  0.3646876811981201,\n",
              "  0.36378005146980286,\n",
              "  0.3640969395637512,\n",
              "  0.36443954706192017,\n",
              "  0.36374202370643616,\n",
              "  0.36408182978630066,\n",
              "  0.36419567465782166,\n",
              "  0.36413413286209106,\n",
              "  0.3637080788612366,\n",
              "  0.36425256729125977,\n",
              "  0.36436256766319275,\n",
              "  0.36413660645484924,\n",
              "  0.36367374658584595,\n",
              "  0.36387842893600464,\n",
              "  0.3636602461338043,\n",
              "  0.3633368909358978,\n",
              "  0.3635379374027252,\n",
              "  0.36337968707084656,\n",
              "  0.3630317747592926,\n",
              "  0.36310046911239624,\n",
              "  0.36338183283805847,\n",
              "  0.36322516202926636,\n",
              "  0.363725870847702,\n",
              "  0.3639019727706909,\n",
              "  0.3635285496711731,\n",
              "  0.36318671703338623,\n",
              "  0.36291977763175964,\n",
              "  0.3627632260322571,\n",
              "  0.3634473979473114,\n",
              "  0.36336472630500793,\n",
              "  0.36328423023223877,\n",
              "  0.3636838495731354,\n",
              "  0.3632984757423401,\n",
              "  0.36310842633247375,\n",
              "  0.3628900945186615,\n",
              "  0.3631168603897095,\n",
              "  0.36294201016426086,\n",
              "  0.3632935881614685,\n",
              "  0.3635096549987793,\n",
              "  0.36338818073272705,\n",
              "  0.3632580041885376,\n",
              "  0.36311179399490356,\n",
              "  0.362605482339859],\n",
              " 'accuracy': [0.779163658618927,\n",
              "  0.7930702567100525,\n",
              "  0.8067804574966431,\n",
              "  0.8139694929122925,\n",
              "  0.8191549777984619,\n",
              "  0.8213647603988647,\n",
              "  0.8242521286010742,\n",
              "  0.8258038759231567,\n",
              "  0.8275323510169983,\n",
              "  0.828877866268158,\n",
              "  0.8284162282943726,\n",
              "  0.8308420777320862,\n",
              "  0.8305179476737976,\n",
              "  0.8304197788238525,\n",
              "  0.8305867314338684,\n",
              "  0.8328258991241455,\n",
              "  0.8325018286705017,\n",
              "  0.8332973122596741,\n",
              "  0.8335330486297607,\n",
              "  0.8337000012397766,\n",
              "  0.8342205286026001,\n",
              "  0.8332187533378601,\n",
              "  0.8338767886161804,\n",
              "  0.8353499174118042,\n",
              "  0.8339749574661255,\n",
              "  0.8353793621063232,\n",
              "  0.8358311653137207,\n",
              "  0.8353008031845093,\n",
              "  0.8351632952690125,\n",
              "  0.8356936573982239,\n",
              "  0.8359588384628296,\n",
              "  0.8363221883773804,\n",
              "  0.8358998894691467,\n",
              "  0.8363025784492493,\n",
              "  0.8364891409873962,\n",
              "  0.835526704788208,\n",
              "  0.8367739915847778,\n",
              "  0.835526704788208,\n",
              "  0.8364105820655823,\n",
              "  0.8375203609466553,\n",
              "  0.8365186452865601,\n",
              "  0.8369114995002747,\n",
              "  0.8372552394866943,\n",
              "  0.836567759513855,\n",
              "  0.8375400304794312,\n",
              "  0.8374418020248413,\n",
              "  0.8381292819976807,\n",
              "  0.8369802236557007,\n",
              "  0.8388462066650391,\n",
              "  0.8375989198684692,\n",
              "  0.8378346562385559,\n",
              "  0.8381980061531067,\n",
              "  0.8383355140686035,\n",
              "  0.8370293378829956,\n",
              "  0.8391703367233276,\n",
              "  0.8380212783813477,\n",
              "  0.8386498093605042,\n",
              "  0.8389149904251099,\n",
              "  0.8386399745941162,\n",
              "  0.8378936052322388,\n",
              "  0.837677538394928,\n",
              "  0.8384533524513245,\n",
              "  0.8388658761978149,\n",
              "  0.8385221362113953,\n",
              "  0.8390328288078308,\n",
              "  0.8389935493469238,\n",
              "  0.8390033841133118,\n",
              "  0.838924765586853,\n",
              "  0.8391605019569397,\n",
              "  0.8395336866378784,\n",
              "  0.8389444351196289,\n",
              "  0.8385417461395264,\n",
              "  0.8384631872177124,\n",
              "  0.8391212224960327,\n",
              "  0.839857816696167,\n",
              "  0.8397694230079651,\n",
              "  0.8396024703979492,\n",
              "  0.8391899466514587,\n",
              "  0.8397497534751892,\n",
              "  0.8396908044815063,\n",
              "  0.839897096157074,\n",
              "  0.839847981929779,\n",
              "  0.8408988118171692,\n",
              "  0.8396515250205994,\n",
              "  0.8398774266242981,\n",
              "  0.8393961787223816,\n",
              "  0.8404273986816406,\n",
              "  0.840044379234314,\n",
              "  0.8404863476753235,\n",
              "  0.8398283123970032,\n",
              "  0.8397399187088013,\n",
              "  0.8409184813499451,\n",
              "  0.8402113318443298,\n",
              "  0.8398774266242981,\n",
              "  0.841154158115387,\n",
              "  0.8399068713188171,\n",
              "  0.8394747972488403,\n",
              "  0.8404175639152527,\n",
              "  0.8402898907661438,\n",
              "  0.8406041860580444,\n",
              "  0.8399068713188171,\n",
              "  0.8397301435470581,\n",
              "  0.8403685092926025,\n",
              "  0.8403586745262146,\n",
              "  0.8398087024688721,\n",
              "  0.8408300876617432,\n",
              "  0.8408792018890381,\n",
              "  0.8394452929496765,\n",
              "  0.8406434655189514,\n",
              "  0.8409479260444641,\n",
              "  0.8412818312644958,\n",
              "  0.8407318592071533,\n",
              "  0.8406434655189514,\n",
              "  0.8416354060173035,\n",
              "  0.8409773707389832,\n",
              "  0.8405550718307495,\n",
              "  0.8406533002853394,\n",
              "  0.8412818312644958,\n",
              "  0.8416943550109863,\n",
              "  0.8407122492790222,\n",
              "  0.8406434655189514,\n",
              "  0.8412425518035889,\n",
              "  0.8410559892654419,\n",
              "  0.8405649065971375,\n",
              "  0.8411639928817749,\n",
              "  0.8407809734344482,\n",
              "  0.8412523865699768,\n",
              "  0.8413015007972717,\n",
              "  0.8419005870819092,\n",
              "  0.8407613039016724,\n",
              "  0.8412131071090698,\n",
              "  0.8411247134208679,\n",
              "  0.8417826890945435,\n",
              "  0.8412229418754578,\n",
              "  0.8406041860580444,\n",
              "  0.8409086465835571,\n",
              "  0.8414978981018066,\n",
              "  0.8406925797462463,\n",
              "  0.841144323348999,\n",
              "  0.8413211107254028,\n",
              "  0.8408399224281311,\n",
              "  0.8413702249526978,\n",
              "  0.8417925238609314,\n",
              "  0.8408104181289673,\n",
              "  0.8411345481872559,\n",
              "  0.841144323348999,\n",
              "  0.8416550159454346,\n",
              "  0.8415371775627136,\n",
              "  0.8419791460037231,\n",
              "  0.8419104218482971,\n",
              "  0.8417336344718933,\n",
              "  0.8414880633354187,\n",
              "  0.8413211107254028,\n",
              "  0.8411836624145508,\n",
              "  0.8415961265563965,\n",
              "  0.8421657681465149,\n",
              "  0.8416943550109863,\n",
              "  0.8414095044136047,\n",
              "  0.8423916101455688,\n",
              "  0.8421755433082581,\n",
              "  0.8417041301727295,\n",
              "  0.8415470123291016,\n",
              "  0.8417434096336365,\n",
              "  0.842214822769165,\n",
              "  0.8425291180610657,\n",
              "  0.84226393699646,\n",
              "  0.8413211107254028,\n",
              "  0.8420969843864441,\n",
              "  0.8422443270683289,\n",
              "  0.8423327207565308,\n",
              "  0.8411738276481628,\n",
              "  0.8423327207565308,\n",
              "  0.8428728580474854,\n",
              "  0.8417925238609314,\n",
              "  0.8423130512237549,\n",
              "  0.8424800038337708,\n",
              "  0.8420478701591492,\n",
              "  0.8413898944854736,\n",
              "  0.8425487875938416,\n",
              "  0.8414487838745117,\n",
              "  0.8417729139328003,\n",
              "  0.8415568470954895,\n",
              "  0.8424898386001587,\n",
              "  0.8425880670547485,\n",
              "  0.841193437576294,\n",
              "  0.8419693112373352,\n",
              "  0.8424014449119568,\n",
              "  0.84211665391922,\n",
              "  0.8418907523155212,\n",
              "  0.8419104218482971,\n",
              "  0.8421264290809631,\n",
              "  0.8415764570236206,\n",
              "  0.842077374458313,\n",
              "  0.8422050476074219,\n",
              "  0.8416845202445984,\n",
              "  0.843295156955719,\n",
              "  0.8430103659629822,\n",
              "  0.8426273465156555,\n",
              "  0.8426960706710815,\n",
              "  0.8428728580474854,\n",
              "  0.8425978422164917,\n",
              "  0.842214822769165,\n",
              "  0.8418318033218384,\n",
              "  0.8419889807701111,\n",
              "  0.8423424959182739,\n",
              "  0.8427157402038574,\n",
              "  0.8426567912101746,\n",
              "  0.8424505591392517,\n",
              "  0.8424603939056396,\n",
              "  0.8419104218482971,\n",
              "  0.8425291180610657,\n",
              "  0.84226393699646,\n",
              "  0.8427451848983765,\n",
              "  0.843226432800293,\n",
              "  0.8429318070411682,\n",
              "  0.8432362079620361,\n",
              "  0.8424112796783447,\n",
              "  0.8423424959182739,\n",
              "  0.8431282043457031,\n",
              "  0.8426666259765625,\n",
              "  0.8437076210975647,\n",
              "  0.8430398106575012,\n",
              "  0.8424407243728638,\n",
              "  0.8428237438201904,\n",
              "  0.8437469601631165,\n",
              "  0.843324601650238,\n",
              "  0.8426764607429504,\n",
              "  0.8428630232810974,\n",
              "  0.843226432800293,\n",
              "  0.8421755433082581,\n",
              "  0.8428434133529663,\n",
              "  0.8429415822029114,\n",
              "  0.8434719443321228,\n",
              "  0.843187153339386,\n",
              "  0.8435799479484558,\n",
              "  0.8426862359046936,\n",
              "  0.843255877494812,\n",
              "  0.8431674838066101,\n",
              "  0.8425978422164917,\n",
              "  0.8433835506439209,\n",
              "  0.843147873878479,\n",
              "  0.8433148264884949,\n",
              "  0.8428237438201904,\n",
              "  0.8434032201766968,\n",
              "  0.8436978459358215,\n",
              "  0.8431576490402222,\n",
              "  0.8423817753791809,\n",
              "  0.8435897827148438,\n",
              "  0.8420478701591492,\n",
              "  0.8429219722747803,\n",
              "  0.8426862359046936,\n",
              "  0.8432362079620361,\n",
              "  0.8432362079620361,\n",
              "  0.843285322189331,\n",
              "  0.8434326648712158,\n",
              "  0.8434129953384399,\n",
              "  0.8438549637794495,\n",
              "  0.8432460427284241,\n",
              "  0.8440317511558533,\n",
              "  0.843226432800293,\n",
              "  0.8427550196647644,\n",
              "  0.8433835506439209,\n",
              "  0.8434817790985107,\n",
              "  0.8430692553520203,\n",
              "  0.8430889248847961,\n",
              "  0.8429514169692993,\n",
              "  0.8438844084739685,\n",
              "  0.8435897827148438,\n",
              "  0.843334436416626,\n",
              "  0.8434915542602539,\n",
              "  0.8433049917221069,\n",
              "  0.843363881111145,\n",
              "  0.8437174558639526,\n",
              "  0.8435996174812317,\n",
              "  0.8434915542602539,\n",
              "  0.8438156843185425,\n",
              "  0.8439531922340393,\n",
              "  0.843226432800293,\n",
              "  0.8436683416366577,\n",
              "  0.8437960147857666,\n",
              "  0.843177318572998,\n",
              "  0.8430790901184082,\n",
              "  0.8439826369285583,\n",
              "  0.8438352942466736,\n",
              "  0.8441987037658691,\n",
              "  0.8440120816230774,\n",
              "  0.8434326648712158,\n",
              "  0.843324601650238,\n",
              "  0.8436585664749146,\n",
              "  0.8434326648712158,\n",
              "  0.8438156843185425,\n",
              "  0.8437272906303406,\n",
              "  0.8426666259765625,\n",
              "  0.8440513610839844,\n",
              "  0.8430398106575012,\n",
              "  0.8429612517356873,\n",
              "  0.8438451290130615,\n",
              "  0.8433933854103088,\n",
              "  0.8440219163894653,\n",
              "  0.844444215297699],\n",
              " 'val_loss': [0.4800125062465668,\n",
              "  0.4376412034034729,\n",
              "  0.4154154360294342,\n",
              "  0.4028339385986328,\n",
              "  0.39459824562072754,\n",
              "  0.38911452889442444,\n",
              "  0.3853289484977722,\n",
              "  0.3824988305568695,\n",
              "  0.38007450103759766,\n",
              "  0.37820884585380554,\n",
              "  0.3766515851020813,\n",
              "  0.3755536377429962,\n",
              "  0.3744280934333801,\n",
              "  0.3733696937561035,\n",
              "  0.3726159632205963,\n",
              "  0.37198829650878906,\n",
              "  0.3713299036026001,\n",
              "  0.37076517939567566,\n",
              "  0.37028443813323975,\n",
              "  0.36976712942123413,\n",
              "  0.3693329095840454,\n",
              "  0.36903807520866394,\n",
              "  0.36861705780029297,\n",
              "  0.3682580590248108,\n",
              "  0.3679620623588562,\n",
              "  0.36769989132881165,\n",
              "  0.3673788905143738,\n",
              "  0.36708128452301025,\n",
              "  0.36688685417175293,\n",
              "  0.36652815341949463,\n",
              "  0.36633262038230896,\n",
              "  0.36610880494117737,\n",
              "  0.36594071984291077,\n",
              "  0.36578962206840515,\n",
              "  0.3655136823654175,\n",
              "  0.36535924673080444,\n",
              "  0.36525437235832214,\n",
              "  0.36504438519477844,\n",
              "  0.36485952138900757,\n",
              "  0.3647288978099823,\n",
              "  0.364552766084671,\n",
              "  0.3643929958343506,\n",
              "  0.36434468626976013,\n",
              "  0.3640405833721161,\n",
              "  0.36399832367897034,\n",
              "  0.3638463020324707,\n",
              "  0.3636792004108429,\n",
              "  0.3636209964752197,\n",
              "  0.3635181188583374,\n",
              "  0.3634006381034851,\n",
              "  0.36328667402267456,\n",
              "  0.3631858825683594,\n",
              "  0.3629661500453949,\n",
              "  0.3628779351711273,\n",
              "  0.3627989590167999,\n",
              "  0.36265966296195984,\n",
              "  0.3625645041465759,\n",
              "  0.36246609687805176,\n",
              "  0.3623746633529663,\n",
              "  0.3622870147228241,\n",
              "  0.3621422052383423,\n",
              "  0.3620379567146301,\n",
              "  0.36190617084503174,\n",
              "  0.36182940006256104,\n",
              "  0.3617675006389618,\n",
              "  0.3616655468940735,\n",
              "  0.3615196943283081,\n",
              "  0.3615626394748688,\n",
              "  0.3615022599697113,\n",
              "  0.36130356788635254,\n",
              "  0.3612620532512665,\n",
              "  0.36112916469573975,\n",
              "  0.36107760667800903,\n",
              "  0.3610534369945526,\n",
              "  0.3609369397163391,\n",
              "  0.3608852028846741,\n",
              "  0.36085155606269836,\n",
              "  0.3607291877269745,\n",
              "  0.3606666624546051,\n",
              "  0.36054539680480957,\n",
              "  0.3605080246925354,\n",
              "  0.36038267612457275,\n",
              "  0.3603270947933197,\n",
              "  0.3602837324142456,\n",
              "  0.3601841330528259,\n",
              "  0.3601219654083252,\n",
              "  0.36008280515670776,\n",
              "  0.3600282669067383,\n",
              "  0.35997387766838074,\n",
              "  0.3598678410053253,\n",
              "  0.35981106758117676,\n",
              "  0.35976675152778625,\n",
              "  0.35970985889434814,\n",
              "  0.3596368432044983,\n",
              "  0.3595622777938843,\n",
              "  0.3594703674316406,\n",
              "  0.3594118654727936,\n",
              "  0.35940828919410706,\n",
              "  0.3593783378601074,\n",
              "  0.3593541085720062,\n",
              "  0.3592451512813568,\n",
              "  0.3591445982456207,\n",
              "  0.35913416743278503,\n",
              "  0.359115868806839,\n",
              "  0.35903051495552063,\n",
              "  0.35898357629776,\n",
              "  0.3589136600494385,\n",
              "  0.35889676213264465,\n",
              "  0.3588319420814514,\n",
              "  0.35874664783477783,\n",
              "  0.3586961627006531,\n",
              "  0.358643114566803,\n",
              "  0.35859447717666626,\n",
              "  0.35856980085372925,\n",
              "  0.3585270047187805,\n",
              "  0.3584936261177063,\n",
              "  0.35846197605133057,\n",
              "  0.35842689871788025,\n",
              "  0.3583492636680603,\n",
              "  0.3583217263221741,\n",
              "  0.35824841260910034,\n",
              "  0.3581920862197876,\n",
              "  0.35815826058387756,\n",
              "  0.3581128418445587,\n",
              "  0.35805296897888184,\n",
              "  0.35801056027412415,\n",
              "  0.3580148220062256,\n",
              "  0.35793933272361755,\n",
              "  0.35787102580070496,\n",
              "  0.3578355610370636,\n",
              "  0.35784125328063965,\n",
              "  0.3577820956707001,\n",
              "  0.35778146982192993,\n",
              "  0.35773947834968567,\n",
              "  0.3576398193836212,\n",
              "  0.3575773537158966,\n",
              "  0.3575298488140106,\n",
              "  0.357488751411438,\n",
              "  0.3574858605861664,\n",
              "  0.3574706017971039,\n",
              "  0.35742121934890747,\n",
              "  0.3573719561100006,\n",
              "  0.35735952854156494,\n",
              "  0.35732191801071167,\n",
              "  0.35728561878204346,\n",
              "  0.35725513100624084,\n",
              "  0.3571903705596924,\n",
              "  0.3571151793003082,\n",
              "  0.35712385177612305,\n",
              "  0.35708490014076233,\n",
              "  0.35704123973846436,\n",
              "  0.3569989502429962,\n",
              "  0.3569854497909546,\n",
              "  0.35698577761650085,\n",
              "  0.3569311797618866,\n",
              "  0.35688045620918274,\n",
              "  0.3568568229675293,\n",
              "  0.35676103830337524,\n",
              "  0.35672909021377563,\n",
              "  0.35672464966773987,\n",
              "  0.35667985677719116,\n",
              "  0.35668957233428955,\n",
              "  0.3566001057624817,\n",
              "  0.35653626918792725,\n",
              "  0.3565519154071808,\n",
              "  0.3565463423728943,\n",
              "  0.3564780056476593,\n",
              "  0.356505811214447,\n",
              "  0.356427401304245,\n",
              "  0.3563555181026459,\n",
              "  0.3563646376132965,\n",
              "  0.3563239872455597,\n",
              "  0.35626065731048584,\n",
              "  0.35622769594192505,\n",
              "  0.3562467098236084,\n",
              "  0.3562544882297516,\n",
              "  0.3561907410621643,\n",
              "  0.3561445474624634,\n",
              "  0.35612058639526367,\n",
              "  0.3560607433319092,\n",
              "  0.35602250695228577,\n",
              "  0.35601216554641724,\n",
              "  0.35596704483032227,\n",
              "  0.3559138774871826,\n",
              "  0.3558865785598755,\n",
              "  0.35586342215538025,\n",
              "  0.3558766543865204,\n",
              "  0.35583195090293884,\n",
              "  0.3558535873889923,\n",
              "  0.3557872474193573,\n",
              "  0.35575538873672485,\n",
              "  0.3557101786136627,\n",
              "  0.35564884543418884,\n",
              "  0.35565540194511414,\n",
              "  0.35562241077423096,\n",
              "  0.35561543703079224,\n",
              "  0.35554543137550354,\n",
              "  0.355490505695343,\n",
              "  0.35551396012306213,\n",
              "  0.3554864823818207,\n",
              "  0.35545089840888977,\n",
              "  0.3554278612136841,\n",
              "  0.35538700222969055,\n",
              "  0.35536661744117737,\n",
              "  0.35534724593162537,\n",
              "  0.35526567697525024,\n",
              "  0.3553074300289154,\n",
              "  0.35529929399490356,\n",
              "  0.35523372888565063,\n",
              "  0.35522541403770447,\n",
              "  0.3552466332912445,\n",
              "  0.35519447922706604,\n",
              "  0.35513532161712646,\n",
              "  0.35509559512138367,\n",
              "  0.35509639978408813,\n",
              "  0.3550816476345062,\n",
              "  0.35505902767181396,\n",
              "  0.35501742362976074,\n",
              "  0.3549599349498749,\n",
              "  0.35492852330207825,\n",
              "  0.3549315631389618,\n",
              "  0.35489121079444885,\n",
              "  0.35491952300071716,\n",
              "  0.35487625002861023,\n",
              "  0.3548165559768677,\n",
              "  0.35478827357292175,\n",
              "  0.35477057099342346,\n",
              "  0.354741632938385,\n",
              "  0.3547258675098419,\n",
              "  0.3546878695487976,\n",
              "  0.35468587279319763,\n",
              "  0.3546326458454132,\n",
              "  0.3546103835105896,\n",
              "  0.35463687777519226,\n",
              "  0.35460373759269714,\n",
              "  0.3545703887939453,\n",
              "  0.35454773902893066,\n",
              "  0.35453444719314575,\n",
              "  0.3544924557209015,\n",
              "  0.3544272184371948,\n",
              "  0.35447821021080017,\n",
              "  0.35440582036972046,\n",
              "  0.35438960790634155,\n",
              "  0.35439035296440125,\n",
              "  0.3543405830860138,\n",
              "  0.3543719947338104,\n",
              "  0.3543303906917572,\n",
              "  0.35429421067237854,\n",
              "  0.35428205132484436,\n",
              "  0.3542441427707672,\n",
              "  0.3542068302631378,\n",
              "  0.35418590903282166,\n",
              "  0.35418975353240967,\n",
              "  0.3541722595691681,\n",
              "  0.35410431027412415,\n",
              "  0.3540689945220947,\n",
              "  0.3540859818458557,\n",
              "  0.35404980182647705,\n",
              "  0.3540216386318207,\n",
              "  0.35401132702827454,\n",
              "  0.35399505496025085,\n",
              "  0.35400140285491943,\n",
              "  0.3539258539676666,\n",
              "  0.353965699672699,\n",
              "  0.35391607880592346,\n",
              "  0.35387861728668213,\n",
              "  0.3538612723350525,\n",
              "  0.3538743257522583,\n",
              "  0.3538520336151123,\n",
              "  0.3538268506526947,\n",
              "  0.35379284620285034,\n",
              "  0.35376399755477905,\n",
              "  0.3537364900112152,\n",
              "  0.3537217676639557,\n",
              "  0.35370954871177673,\n",
              "  0.35367289185523987,\n",
              "  0.35364586114883423,\n",
              "  0.3536636531352997,\n",
              "  0.3536602854728699,\n",
              "  0.35359930992126465,\n",
              "  0.35357022285461426,\n",
              "  0.3535629212856293,\n",
              "  0.3535291254520416,\n",
              "  0.35346922278404236,\n",
              "  0.35348260402679443,\n",
              "  0.35346880555152893,\n",
              "  0.35345086455345154,\n",
              "  0.3534218966960907,\n",
              "  0.3533984124660492,\n",
              "  0.35337236523628235,\n",
              "  0.3533558249473572,\n",
              "  0.35332512855529785,\n",
              "  0.35332852602005005,\n",
              "  0.353305846452713,\n",
              "  0.35333365201950073,\n",
              "  0.3532785475254059,\n",
              "  0.3532607853412628,\n",
              "  0.35322022438049316,\n",
              "  0.3532048761844635,\n",
              "  0.35318896174430847],\n",
              " 'val_accuracy': [0.7909619808197021,\n",
              "  0.8136257529258728,\n",
              "  0.822287917137146,\n",
              "  0.8280168771743774,\n",
              "  0.8310417532920837,\n",
              "  0.8322333693504333,\n",
              "  0.8338145613670349,\n",
              "  0.8355103135108948,\n",
              "  0.8366332054138184,\n",
              "  0.8379164934158325,\n",
              "  0.8384206295013428,\n",
              "  0.8387414813041687,\n",
              "  0.838924765586853,\n",
              "  0.8397039175033569,\n",
              "  0.8398184776306152,\n",
              "  0.8402310013771057,\n",
              "  0.840276837348938,\n",
              "  0.8405289053916931,\n",
              "  0.841193437576294,\n",
              "  0.8415371775627136,\n",
              "  0.8416746854782104,\n",
              "  0.8422017693519592,\n",
              "  0.8422017693519592,\n",
              "  0.8424767255783081,\n",
              "  0.842797577381134,\n",
              "  0.8429808616638184,\n",
              "  0.843187153339386,\n",
              "  0.8430954813957214,\n",
              "  0.8432787656784058,\n",
              "  0.8434392213821411,\n",
              "  0.8433704376220703,\n",
              "  0.8434621095657349,\n",
              "  0.8434162735939026,\n",
              "  0.843645453453064,\n",
              "  0.8433933854103088,\n",
              "  0.843255877494812,\n",
              "  0.8433475494384766,\n",
              "  0.8435308933258057,\n",
              "  0.8435079455375671,\n",
              "  0.8435537815093994,\n",
              "  0.8435996174812317,\n",
              "  0.8435079455375671,\n",
              "  0.8438058495521545,\n",
              "  0.84371417760849,\n",
              "  0.843645453453064,\n",
              "  0.8436912894248962,\n",
              "  0.8440120816230774,\n",
              "  0.8439891934394836,\n",
              "  0.8441267013549805,\n",
              "  0.8440808653831482,\n",
              "  0.8441267013549805,\n",
              "  0.8441267013549805,\n",
              "  0.8443329334259033,\n",
              "  0.8444016575813293,\n",
              "  0.844287097454071,\n",
              "  0.8443329334259033,\n",
              "  0.8445391654968262,\n",
              "  0.8445391654968262,\n",
              "  0.844676673412323,\n",
              "  0.8445391654968262,\n",
              "  0.8447683453559875,\n",
              "  0.8446537256240845,\n",
              "  0.8449057936668396,\n",
              "  0.8448829054832458,\n",
              "  0.8449057936668396,\n",
              "  0.8451120853424072,\n",
              "  0.8452724814414978,\n",
              "  0.845203697681427,\n",
              "  0.8453183174133301,\n",
              "  0.8453183174133301,\n",
              "  0.845203697681427,\n",
              "  0.8453412055969238,\n",
              "  0.8453412055969238,\n",
              "  0.8454787135124207,\n",
              "  0.8455703854560852,\n",
              "  0.8454557657241821,\n",
              "  0.8456162214279175,\n",
              "  0.845707893371582,\n",
              "  0.8457537293434143,\n",
              "  0.8457307815551758,\n",
              "  0.8457307815551758,\n",
              "  0.8456849455833435,\n",
              "  0.8457995057106018,\n",
              "  0.8457766175270081,\n",
              "  0.8458224534988403,\n",
              "  0.8458453416824341,\n",
              "  0.8458682894706726,\n",
              "  0.8459828495979309,\n",
              "  0.8460057973861694,\n",
              "  0.8460516333580017,\n",
              "  0.8459599614143372,\n",
              "  0.8459141254425049,\n",
              "  0.8457766175270081,\n",
              "  0.8459370136260986,\n",
              "  0.8460745215415955,\n",
              "  0.8461432456970215,\n",
              "  0.8462120294570923,\n",
              "  0.8461890816688538,\n",
              "  0.846234917640686,\n",
              "  0.8462578654289246,\n",
              "  0.8463265895843506,\n",
              "  0.8463953137397766,\n",
              "  0.8463953137397766,\n",
              "  0.8462578654289246,\n",
              "  0.8463495373725891,\n",
              "  0.8463495373725891,\n",
              "  0.8463495373725891,\n",
              "  0.8463953137397766,\n",
              "  0.8464182615280151,\n",
              "  0.8462578654289246,\n",
              "  0.8463724255561829,\n",
              "  0.8464182615280151,\n",
              "  0.8464869856834412,\n",
              "  0.8464869856834412,\n",
              "  0.8465099334716797,\n",
              "  0.846555769443512,\n",
              "  0.8466703295707703,\n",
              "  0.8466474413871765,\n",
              "  0.846624493598938,\n",
              "  0.8466932773590088,\n",
              "  0.8468995094299316,\n",
              "  0.8468995094299316,\n",
              "  0.8468307256698608,\n",
              "  0.8468536734580994,\n",
              "  0.8469223976135254,\n",
              "  0.8470369577407837,\n",
              "  0.8469223976135254,\n",
              "  0.8470599055290222,\n",
              "  0.8470599055290222,\n",
              "  0.8471057415008545,\n",
              "  0.8470140695571899,\n",
              "  0.8471744656562805,\n",
              "  0.8469911813735962,\n",
              "  0.847082793712616,\n",
              "  0.847197413444519,\n",
              "  0.847197413444519,\n",
              "  0.8474265336990356,\n",
              "  0.8474723696708679,\n",
              "  0.8473349213600159,\n",
              "  0.8473806977272034,\n",
              "  0.8473119735717773,\n",
              "  0.8473578095436096,\n",
              "  0.8473119735717773,\n",
              "  0.8474265336990356,\n",
              "  0.8474036455154419,\n",
              "  0.8474494814872742,\n",
              "  0.8475411534309387,\n",
              "  0.8475411534309387,\n",
              "  0.8474953174591064,\n",
              "  0.8475640416145325,\n",
              "  0.8476098775863647,\n",
              "  0.8476098775863647,\n",
              "  0.8476328253746033,\n",
              "  0.847586989402771,\n",
              "  0.847586989402771,\n",
              "  0.847655713558197,\n",
              "  0.8476786017417908,\n",
              "  0.8477702736854553,\n",
              "  0.8477932214736938,\n",
              "  0.847724437713623,\n",
              "  0.8477932214736938,\n",
              "  0.847724437713623,\n",
              "  0.8478848934173584,\n",
              "  0.8477702736854553,\n",
              "  0.8476786017417908,\n",
              "  0.8477015495300293,\n",
              "  0.8476098775863647,\n",
              "  0.8478619456291199,\n",
              "  0.8477473855018616,\n",
              "  0.847655713558197,\n",
              "  0.8477702736854553,\n",
              "  0.8478619456291199,\n",
              "  0.8479536175727844,\n",
              "  0.8479077816009521,\n",
              "  0.847724437713623,\n",
              "  0.8477702736854553,\n",
              "  0.8479994535446167,\n",
              "  0.8480681777000427,\n",
              "  0.8479994535446167,\n",
              "  0.8479765057563782,\n",
              "  0.848045289516449,\n",
              "  0.8479994535446167,\n",
              "  0.8480681777000427,\n",
              "  0.8480911254882812,\n",
              "  0.8480223417282104,\n",
              "  0.8478619456291199,\n",
              "  0.8477932214736938,\n",
              "  0.8478848934173584,\n",
              "  0.8479765057563782,\n",
              "  0.8479765057563782,\n",
              "  0.8479077816009521,\n",
              "  0.8479307293891907,\n",
              "  0.8479765057563782,\n",
              "  0.848045289516449,\n",
              "  0.8479994535446167,\n",
              "  0.8479994535446167,\n",
              "  0.8479536175727844,\n",
              "  0.8480223417282104,\n",
              "  0.848045289516449,\n",
              "  0.8481598496437073,\n",
              "  0.8481827974319458,\n",
              "  0.848114013671875,\n",
              "  0.8480911254882812,\n",
              "  0.8480911254882812,\n",
              "  0.8480911254882812,\n",
              "  0.8481827974319458,\n",
              "  0.8480223417282104,\n",
              "  0.8480911254882812,\n",
              "  0.8480911254882812,\n",
              "  0.8481827974319458,\n",
              "  0.8480911254882812,\n",
              "  0.8481369614601135,\n",
              "  0.8481827974319458,\n",
              "  0.8481369614601135,\n",
              "  0.848114013671875,\n",
              "  0.8480681777000427,\n",
              "  0.8481827974319458,\n",
              "  0.8482286334037781,\n",
              "  0.8481827974319458,\n",
              "  0.8482286334037781,\n",
              "  0.8481598496437073,\n",
              "  0.8482286334037781,\n",
              "  0.8482286334037781,\n",
              "  0.8482515215873718,\n",
              "  0.8481369614601135,\n",
              "  0.8482515215873718,\n",
              "  0.8482286334037781,\n",
              "  0.8481827974319458,\n",
              "  0.8483202457427979,\n",
              "  0.8481598496437073,\n",
              "  0.8482515215873718,\n",
              "  0.8481598496437073,\n",
              "  0.8481827974319458,\n",
              "  0.8484807014465332,\n",
              "  0.8484119176864624,\n",
              "  0.8484348654747009,\n",
              "  0.8483660817146301,\n",
              "  0.8484348654747009,\n",
              "  0.8483202457427979,\n",
              "  0.8483660817146301,\n",
              "  0.8484577536582947,\n",
              "  0.8482973575592041,\n",
              "  0.8483660817146301,\n",
              "  0.8484348654747009,\n",
              "  0.8482973575592041,\n",
              "  0.8484119176864624,\n",
              "  0.8483431935310364,\n",
              "  0.8484348654747009,\n",
              "  0.8483890295028687,\n",
              "  0.8483890295028687,\n",
              "  0.8485494256019592,\n",
              "  0.8485265374183655,\n",
              "  0.8484577536582947,\n",
              "  0.8484807014465332,\n",
              "  0.8485265374183655,\n",
              "  0.8485952615737915,\n",
              "  0.8486181497573853,\n",
              "  0.8487327694892883,\n",
              "  0.848686933517456,\n",
              "  0.848686933517456,\n",
              "  0.8487098217010498,\n",
              "  0.8487327694892883,\n",
              "  0.8486181497573853,\n",
              "  0.8487327694892883,\n",
              "  0.8486410975456238,\n",
              "  0.8486410975456238,\n",
              "  0.848686933517456,\n",
              "  0.848686933517456,\n",
              "  0.8486181497573853,\n",
              "  0.8485494256019592,\n",
              "  0.8485952615737915,\n",
              "  0.8486181497573853,\n",
              "  0.8485723733901978,\n",
              "  0.8485265374183655,\n",
              "  0.848503589630127,\n",
              "  0.8486410975456238,\n",
              "  0.8486639857292175,\n",
              "  0.8486410975456238,\n",
              "  0.8486639857292175,\n",
              "  0.8487098217010498,\n",
              "  0.8487556576728821,\n",
              "  0.8487327694892883,\n",
              "  0.8488244414329529,\n",
              "  0.8488244414329529,\n",
              "  0.8488014936447144,\n",
              "  0.8488014936447144,\n",
              "  0.8487786054611206,\n",
              "  0.8488473296165466,\n",
              "  0.8488702774047852,\n",
              "  0.8488473296165466,\n",
              "  0.8488244414329529,\n",
              "  0.8489618897438049,\n",
              "  0.8487327694892883,\n",
              "  0.8487786054611206,\n",
              "  0.8488702774047852,\n",
              "  0.8488702774047852,\n",
              "  0.8488244414329529,\n",
              "  0.8488244414329529,\n",
              "  0.8489160537719727,\n",
              "  0.8489848375320435]}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lossdf=pd.DataFrame(ann.history.history)\n",
        "lossdf.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "7754EDu5mDa1",
        "outputId": "b444eb88-3f4f-4b5a-b582-1d476d13c66f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ypred=ann.predict(xtest)\n",
        "ypred=ypred>0.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-AnhCpwmKS0",
        "outputId": "581660fb-96af-4f7d-c9d0-89ac686c2374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1364/1364 [==============================] - 2s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For evaluation purpose importing classification report .\n",
        "from sklearn.metrics import classification_report\n"
      ],
      "metadata": {
        "id": "oP4kX_zUmPGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(ytest,ypred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgHSaiHcmTyv",
        "outputId": "90700e6c-c451-4ef1-f26c-10f879912f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.95      0.91     34215\n",
            "           1       0.72      0.50      0.59      9423\n",
            "\n",
            "    accuracy                           0.85     43638\n",
            "   macro avg       0.79      0.72      0.75     43638\n",
            "weighted avg       0.84      0.85      0.84     43638\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IsmQS3UEmWT5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}